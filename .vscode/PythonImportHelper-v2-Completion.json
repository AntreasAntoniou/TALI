[
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "dataclasses",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dataclasses",
        "description": "dataclasses",
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "MISSING",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "itertools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "itertools",
        "description": "itertools",
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "pathlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pathlib",
        "description": "pathlib",
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "print",
        "importPath": "rich",
        "description": "rich",
        "isExtraImport": true,
        "detail": "rich",
        "documentation": {}
    },
    {
        "label": "print",
        "importPath": "rich",
        "description": "rich",
        "isExtraImport": true,
        "detail": "rich",
        "documentation": {}
    },
    {
        "label": "print",
        "importPath": "rich",
        "description": "rich",
        "isExtraImport": true,
        "detail": "rich",
        "documentation": {}
    },
    {
        "label": "print",
        "importPath": "rich",
        "description": "rich",
        "isExtraImport": true,
        "detail": "rich",
        "documentation": {}
    },
    {
        "label": "print",
        "importPath": "rich",
        "description": "rich",
        "isExtraImport": true,
        "detail": "rich",
        "documentation": {}
    },
    {
        "label": "print",
        "importPath": "rich",
        "description": "rich",
        "isExtraImport": true,
        "detail": "rich",
        "documentation": {}
    },
    {
        "label": "print",
        "importPath": "rich",
        "description": "rich",
        "isExtraImport": true,
        "detail": "rich",
        "documentation": {}
    },
    {
        "label": "print",
        "importPath": "rich",
        "description": "rich",
        "isExtraImport": true,
        "detail": "rich",
        "documentation": {}
    },
    {
        "label": "print",
        "importPath": "rich",
        "description": "rich",
        "isExtraImport": true,
        "detail": "rich",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tqdm",
        "description": "tqdm",
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "install",
        "importPath": "rich.traceback",
        "description": "rich.traceback",
        "isExtraImport": true,
        "detail": "rich.traceback",
        "documentation": {}
    },
    {
        "label": "install",
        "importPath": "rich.traceback",
        "description": "rich.traceback",
        "isExtraImport": true,
        "detail": "rich.traceback",
        "documentation": {}
    },
    {
        "label": "install",
        "importPath": "rich.traceback",
        "description": "rich.traceback",
        "isExtraImport": true,
        "detail": "rich.traceback",
        "documentation": {}
    },
    {
        "label": "install",
        "importPath": "rich.traceback",
        "description": "rich.traceback",
        "isExtraImport": true,
        "detail": "rich.traceback",
        "documentation": {}
    },
    {
        "label": "install",
        "importPath": "rich.traceback",
        "description": "rich.traceback",
        "isExtraImport": true,
        "detail": "rich.traceback",
        "documentation": {}
    },
    {
        "label": "install",
        "importPath": "rich.traceback",
        "description": "rich.traceback",
        "isExtraImport": true,
        "detail": "rich.traceback",
        "documentation": {}
    },
    {
        "label": "datasets",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datasets",
        "description": "datasets",
        "detail": "datasets",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "datasets",
        "description": "datasets",
        "isExtraImport": true,
        "detail": "datasets",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "importPath": "datasets",
        "description": "datasets",
        "isExtraImport": true,
        "detail": "datasets",
        "documentation": {}
    },
    {
        "label": "ModalityTypes",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "ModalityTypes",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "get_base_modality",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "dataclass_collate",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "AnyModalSample",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "dataclass_collate",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "default_image_transforms",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "ModalityTypes",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "get_base_modality",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "select_subtitles_between_timestamps",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "AnyModalSample",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "ModalityDataSample",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "ModalityTypes",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "TALISchema",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "VideoCLIPScoreSchema",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "ModalityTypes",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "TALIDataset",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "dataclass_collate",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "dataclass_collate",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "dataclass_collate",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "dataclass_collate",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "default_image_transforms",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "ModalityTypes",
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "isExtraImport": true,
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "configurable",
        "importPath": "tali_wit.decorators",
        "description": "tali_wit.decorators",
        "isExtraImport": true,
        "detail": "tali_wit.decorators",
        "documentation": {}
    },
    {
        "label": "configurable",
        "importPath": "tali_wit.decorators",
        "description": "tali_wit.decorators",
        "isExtraImport": true,
        "detail": "tali_wit.decorators",
        "documentation": {}
    },
    {
        "label": "configurable",
        "importPath": "tali_wit.decorators",
        "description": "tali_wit.decorators",
        "isExtraImport": true,
        "detail": "tali_wit.decorators",
        "documentation": {}
    },
    {
        "label": "configurable",
        "importPath": "tali_wit.decorators",
        "description": "tali_wit.decorators",
        "isExtraImport": true,
        "detail": "tali_wit.decorators",
        "documentation": {}
    },
    {
        "label": "configurable",
        "importPath": "tali_wit.decorators",
        "description": "tali_wit.decorators",
        "isExtraImport": true,
        "detail": "tali_wit.decorators",
        "documentation": {}
    },
    {
        "label": "configurable",
        "importPath": "tali_wit.decorators",
        "description": "tali_wit.decorators",
        "isExtraImport": true,
        "detail": "tali_wit.decorators",
        "documentation": {}
    },
    {
        "label": "get_logger",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "load_json",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "save_json",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "get_logger",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "get_hydra_config",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "get_logger",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "get_logger",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "get_logger",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "load_json",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "get_logger",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "load_json",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "set_seed",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "timeout",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "get_logger",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "load_json",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "set_seed",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "get_logger",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "get_logger",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "pretty_config",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "set_seed",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "create_hf_model_repo_and_download_maybe",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "get_logger",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "pretty_config",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "set_seed",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "create_hf_model_repo_and_download_maybe",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "get_logger",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "pretty_config",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "set_seed",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "get_logger",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "load_json",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "save_json",
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "isExtraImport": true,
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "ModalityConfig",
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "isExtraImport": true,
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "extract_all_possible_pairs",
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "isExtraImport": true,
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "extract_all_possible_pairs",
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "isExtraImport": true,
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "TALIModel",
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "isExtraImport": true,
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "TALIModel",
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "isExtraImport": true,
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "TALIModel",
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "isExtraImport": true,
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "extract_all_possible_pairs",
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "isExtraImport": true,
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "TALIBaseDemoTransform",
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "isExtraImport": true,
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "TALIBaseTransformConfig",
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "isExtraImport": true,
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "isExtraImport": true,
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "TALIBase",
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "isExtraImport": true,
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "isExtraImport": true,
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "CustomConcatDataset",
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "isExtraImport": true,
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "isExtraImport": true,
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "get_next_on_error",
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "isExtraImport": true,
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "get_submodality_name",
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "isExtraImport": true,
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "upload",
        "importPath": "distutils.command.upload",
        "description": "distutils.command.upload",
        "isExtraImport": true,
        "detail": "distutils.command.upload",
        "documentation": {}
    },
    {
        "label": "upload",
        "importPath": "distutils.command.upload",
        "description": "distutils.command.upload",
        "isExtraImport": true,
        "detail": "distutils.command.upload",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "importlib.resources",
        "description": "importlib.resources",
        "isExtraImport": true,
        "detail": "importlib.resources",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "importlib.resources",
        "description": "importlib.resources",
        "isExtraImport": true,
        "detail": "importlib.resources",
        "documentation": {}
    },
    {
        "label": "gradio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gradio",
        "description": "gradio",
        "detail": "gradio",
        "documentation": {}
    },
    {
        "label": "torchvision",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision",
        "description": "torchvision",
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "torchaudio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchaudio",
        "description": "torchaudio",
        "detail": "torchaudio",
        "documentation": {}
    },
    {
        "label": "asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio",
        "description": "asyncio",
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "ProcessPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "queue",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "queue",
        "description": "queue",
        "detail": "queue",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "torch.utils.data",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Subset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Subset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Subset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "accelerate",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "accelerate",
        "description": "accelerate",
        "detail": "accelerate",
        "documentation": {}
    },
    {
        "label": "Accelerator",
        "importPath": "accelerate",
        "description": "accelerate",
        "isExtraImport": true,
        "detail": "accelerate",
        "documentation": {}
    },
    {
        "label": "DistributedDataParallelKwargs",
        "importPath": "accelerate",
        "description": "accelerate",
        "isExtraImport": true,
        "detail": "accelerate",
        "documentation": {}
    },
    {
        "label": "Accelerator",
        "importPath": "accelerate",
        "description": "accelerate",
        "isExtraImport": true,
        "detail": "accelerate",
        "documentation": {}
    },
    {
        "label": "Accelerator",
        "importPath": "accelerate",
        "description": "accelerate",
        "isExtraImport": true,
        "detail": "accelerate",
        "documentation": {}
    },
    {
        "label": "Accelerator",
        "importPath": "accelerate",
        "description": "accelerate",
        "isExtraImport": true,
        "detail": "accelerate",
        "documentation": {}
    },
    {
        "label": "Accelerator",
        "importPath": "accelerate",
        "description": "accelerate",
        "isExtraImport": true,
        "detail": "accelerate",
        "documentation": {}
    },
    {
        "label": "Callback",
        "importPath": "tali_wit.callbacks",
        "description": "tali_wit.callbacks",
        "isExtraImport": true,
        "detail": "tali_wit.callbacks",
        "documentation": {}
    },
    {
        "label": "CallbackHandler",
        "importPath": "tali_wit.callbacks",
        "description": "tali_wit.callbacks",
        "isExtraImport": true,
        "detail": "tali_wit.callbacks",
        "documentation": {}
    },
    {
        "label": "Interval",
        "importPath": "tali_wit.callbacks",
        "description": "tali_wit.callbacks",
        "isExtraImport": true,
        "detail": "tali_wit.callbacks",
        "documentation": {}
    },
    {
        "label": "UploadCheckpointsToHuggingFace",
        "importPath": "tali_wit.callbacks",
        "description": "tali_wit.callbacks",
        "isExtraImport": true,
        "detail": "tali_wit.callbacks",
        "documentation": {}
    },
    {
        "label": "Callback",
        "importPath": "tali_wit.callbacks",
        "description": "tali_wit.callbacks",
        "isExtraImport": true,
        "detail": "tali_wit.callbacks",
        "documentation": {}
    },
    {
        "label": "Callback",
        "importPath": "tali_wit.callbacks",
        "description": "tali_wit.callbacks",
        "isExtraImport": true,
        "detail": "tali_wit.callbacks",
        "documentation": {}
    },
    {
        "label": "Interval",
        "importPath": "tali_wit.callbacks",
        "description": "tali_wit.callbacks",
        "isExtraImport": true,
        "detail": "tali_wit.callbacks",
        "documentation": {}
    },
    {
        "label": "ClassificationEvaluator",
        "importPath": "tali_wit.evaluators",
        "description": "tali_wit.evaluators",
        "isExtraImport": true,
        "detail": "tali_wit.evaluators",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "importPath": "tali_wit.evaluators",
        "description": "tali_wit.evaluators",
        "isExtraImport": true,
        "detail": "tali_wit.evaluators",
        "documentation": {}
    },
    {
        "label": "ClassificationEvaluator",
        "importPath": "tali_wit.evaluators",
        "description": "tali_wit.evaluators",
        "isExtraImport": true,
        "detail": "tali_wit.evaluators",
        "documentation": {}
    },
    {
        "label": "ClassificationEvaluator",
        "importPath": "tali_wit.evaluators",
        "description": "tali_wit.evaluators",
        "isExtraImport": true,
        "detail": "tali_wit.evaluators",
        "documentation": {}
    },
    {
        "label": "ClassificationTrainer",
        "importPath": "tali_wit.trainers",
        "description": "tali_wit.trainers",
        "isExtraImport": true,
        "detail": "tali_wit.trainers",
        "documentation": {}
    },
    {
        "label": "Trainer",
        "importPath": "tali_wit.trainers",
        "description": "tali_wit.trainers",
        "isExtraImport": true,
        "detail": "tali_wit.trainers",
        "documentation": {}
    },
    {
        "label": "ClassificationTrainer",
        "importPath": "tali_wit.trainers",
        "description": "tali_wit.trainers",
        "isExtraImport": true,
        "detail": "tali_wit.trainers",
        "documentation": {}
    },
    {
        "label": "ClassificationTrainer",
        "importPath": "tali_wit.trainers",
        "description": "tali_wit.trainers",
        "isExtraImport": true,
        "detail": "tali_wit.trainers",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "floor",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "floor",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "floor",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "floor",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "P",
        "importPath": "regex",
        "description": "regex",
        "isExtraImport": true,
        "detail": "regex",
        "documentation": {}
    },
    {
        "label": "ConfigStore",
        "importPath": "hydra.core.config_store",
        "description": "hydra.core.config_store",
        "isExtraImport": true,
        "detail": "hydra.core.config_store",
        "documentation": {}
    },
    {
        "label": "MISSING",
        "importPath": "hydra_zen",
        "description": "hydra_zen",
        "isExtraImport": true,
        "detail": "hydra_zen",
        "documentation": {}
    },
    {
        "label": "ZenField",
        "importPath": "hydra_zen",
        "description": "hydra_zen",
        "isExtraImport": true,
        "detail": "hydra_zen",
        "documentation": {}
    },
    {
        "label": "builds",
        "importPath": "hydra_zen",
        "description": "hydra_zen",
        "isExtraImport": true,
        "detail": "hydra_zen",
        "documentation": {}
    },
    {
        "label": "make_config",
        "importPath": "hydra_zen",
        "description": "hydra_zen",
        "isExtraImport": true,
        "detail": "hydra_zen",
        "documentation": {}
    },
    {
        "label": "builds",
        "importPath": "hydra_zen",
        "description": "hydra_zen",
        "isExtraImport": true,
        "detail": "hydra_zen",
        "documentation": {}
    },
    {
        "label": "builds",
        "importPath": "hydra_zen",
        "description": "hydra_zen",
        "isExtraImport": true,
        "detail": "hydra_zen",
        "documentation": {}
    },
    {
        "label": "instantiate",
        "importPath": "hydra_zen",
        "description": "hydra_zen",
        "isExtraImport": true,
        "detail": "hydra_zen",
        "documentation": {}
    },
    {
        "label": "instantiate",
        "importPath": "hydra_zen",
        "description": "hydra_zen",
        "isExtraImport": true,
        "detail": "hydra_zen",
        "documentation": {}
    },
    {
        "label": "instantiate",
        "importPath": "hydra_zen",
        "description": "hydra_zen",
        "isExtraImport": true,
        "detail": "hydra_zen",
        "documentation": {}
    },
    {
        "label": "instantiate",
        "importPath": "hydra_zen",
        "description": "hydra_zen",
        "isExtraImport": true,
        "detail": "hydra_zen",
        "documentation": {}
    },
    {
        "label": "CosineLRScheduler",
        "importPath": "timm.scheduler",
        "description": "timm.scheduler",
        "isExtraImport": true,
        "detail": "timm.scheduler",
        "documentation": {}
    },
    {
        "label": "Learner",
        "importPath": "tali_wit.boilerplate",
        "description": "tali_wit.boilerplate",
        "isExtraImport": true,
        "detail": "tali_wit.boilerplate",
        "documentation": {}
    },
    {
        "label": "Learner",
        "importPath": "tali_wit.boilerplate",
        "description": "tali_wit.boilerplate",
        "isExtraImport": true,
        "detail": "tali_wit.boilerplate",
        "documentation": {}
    },
    {
        "label": "Learner",
        "importPath": "tali_wit.boilerplate",
        "description": "tali_wit.boilerplate",
        "isExtraImport": true,
        "detail": "tali_wit.boilerplate",
        "documentation": {}
    },
    {
        "label": "WITBase",
        "importPath": "tali_wit.wit",
        "description": "tali_wit.wit",
        "isExtraImport": true,
        "detail": "tali_wit.wit",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "False_",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "PIL",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PIL",
        "description": "PIL",
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "pyarrow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pyarrow",
        "description": "pyarrow",
        "detail": "pyarrow",
        "documentation": {}
    },
    {
        "label": "pyarrow.dataset",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pyarrow.dataset",
        "description": "pyarrow.dataset",
        "detail": "pyarrow.dataset",
        "documentation": {}
    },
    {
        "label": "pyarrow.parquet",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pyarrow.parquet",
        "description": "pyarrow.parquet",
        "detail": "pyarrow.parquet",
        "documentation": {}
    },
    {
        "label": "EncodedVideo",
        "importPath": "pytorchvideo.data.encoded_video",
        "description": "pytorchvideo.data.encoded_video",
        "isExtraImport": true,
        "detail": "pytorchvideo.data.encoded_video",
        "documentation": {}
    },
    {
        "label": "EncodedVideo",
        "importPath": "pytorchvideo.data.encoded_video",
        "description": "pytorchvideo.data.encoded_video",
        "isExtraImport": true,
        "detail": "pytorchvideo.data.encoded_video",
        "documentation": {}
    },
    {
        "label": "ApplyTransformToKey",
        "importPath": "pytorchvideo.transforms",
        "description": "pytorchvideo.transforms",
        "isExtraImport": true,
        "detail": "pytorchvideo.transforms",
        "documentation": {}
    },
    {
        "label": "ShortSideScale",
        "importPath": "pytorchvideo.transforms",
        "description": "pytorchvideo.transforms",
        "isExtraImport": true,
        "detail": "pytorchvideo.transforms",
        "documentation": {}
    },
    {
        "label": "UniformTemporalSubsample",
        "importPath": "pytorchvideo.transforms",
        "description": "pytorchvideo.transforms",
        "isExtraImport": true,
        "detail": "pytorchvideo.transforms",
        "documentation": {}
    },
    {
        "label": "ApplyTransformToKey",
        "importPath": "pytorchvideo.transforms",
        "description": "pytorchvideo.transforms",
        "isExtraImport": true,
        "detail": "pytorchvideo.transforms",
        "documentation": {}
    },
    {
        "label": "ShortSideScale",
        "importPath": "pytorchvideo.transforms",
        "description": "pytorchvideo.transforms",
        "isExtraImport": true,
        "detail": "pytorchvideo.transforms",
        "documentation": {}
    },
    {
        "label": "ApplyTransformToKey",
        "importPath": "pytorchvideo.transforms",
        "description": "pytorchvideo.transforms",
        "isExtraImport": true,
        "detail": "pytorchvideo.transforms",
        "documentation": {}
    },
    {
        "label": "ShortSideScale",
        "importPath": "pytorchvideo.transforms",
        "description": "pytorchvideo.transforms",
        "isExtraImport": true,
        "detail": "pytorchvideo.transforms",
        "documentation": {}
    },
    {
        "label": "UniformTemporalSubsample",
        "importPath": "pytorchvideo.transforms",
        "description": "pytorchvideo.transforms",
        "isExtraImport": true,
        "detail": "pytorchvideo.transforms",
        "documentation": {}
    },
    {
        "label": "default_collate",
        "importPath": "torch.utils.data.dataloader",
        "description": "torch.utils.data.dataloader",
        "isExtraImport": true,
        "detail": "torch.utils.data.dataloader",
        "documentation": {}
    },
    {
        "label": "Compose",
        "importPath": "torchvision.transforms",
        "description": "torchvision.transforms",
        "isExtraImport": true,
        "detail": "torchvision.transforms",
        "documentation": {}
    },
    {
        "label": "RandomCrop",
        "importPath": "torchvision.transforms",
        "description": "torchvision.transforms",
        "isExtraImport": true,
        "detail": "torchvision.transforms",
        "documentation": {}
    },
    {
        "label": "Resize",
        "importPath": "torchvision.transforms",
        "description": "torchvision.transforms",
        "isExtraImport": true,
        "detail": "torchvision.transforms",
        "documentation": {}
    },
    {
        "label": "ToTensor",
        "importPath": "torchvision.transforms",
        "description": "torchvision.transforms",
        "isExtraImport": true,
        "detail": "torchvision.transforms",
        "documentation": {}
    },
    {
        "label": "Compose",
        "importPath": "torchvision.transforms",
        "description": "torchvision.transforms",
        "isExtraImport": true,
        "detail": "torchvision.transforms",
        "documentation": {}
    },
    {
        "label": "Compose",
        "importPath": "torchvision.transforms",
        "description": "torchvision.transforms",
        "isExtraImport": true,
        "detail": "torchvision.transforms",
        "documentation": {}
    },
    {
        "label": "CenterCropVideo",
        "importPath": "torchvision.transforms._transforms_video",
        "description": "torchvision.transforms._transforms_video",
        "isExtraImport": true,
        "detail": "torchvision.transforms._transforms_video",
        "documentation": {}
    },
    {
        "label": "CenterCropVideo",
        "importPath": "torchvision.transforms._transforms_video",
        "description": "torchvision.transforms._transforms_video",
        "isExtraImport": true,
        "detail": "torchvision.transforms._transforms_video",
        "documentation": {}
    },
    {
        "label": "CenterCropVideo",
        "importPath": "torchvision.transforms._transforms_video",
        "description": "torchvision.transforms._transforms_video",
        "isExtraImport": true,
        "detail": "torchvision.transforms._transforms_video",
        "documentation": {}
    },
    {
        "label": "CLIPProcessor",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "CLIPProcessor",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "WhisperProcessor",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "CLIPModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "CLIPProcessor",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "WhisperModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "WhisperProcessor",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "CLIPProcessor",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "WhisperProcessor",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "WhisperProcessor",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "WhisperForConditionalGeneration",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "torchaudio.transforms",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchaudio.transforms",
        "description": "torchaudio.transforms",
        "detail": "torchaudio.transforms",
        "documentation": {}
    },
    {
        "label": "FrameSelectionMethod",
        "importPath": "tali_wit.frame_extractor",
        "description": "tali_wit.frame_extractor",
        "isExtraImport": true,
        "detail": "tali_wit.frame_extractor",
        "documentation": {}
    },
    {
        "label": "duration_in_seconds_from_path",
        "importPath": "tali_wit.frame_extractor",
        "description": "tali_wit.frame_extractor",
        "isExtraImport": true,
        "detail": "tali_wit.frame_extractor",
        "documentation": {}
    },
    {
        "label": "extract_frames_pyav",
        "importPath": "tali_wit.frame_extractor",
        "description": "tali_wit.frame_extractor",
        "isExtraImport": true,
        "detail": "tali_wit.frame_extractor",
        "documentation": {}
    },
    {
        "label": "extract_frames_torchvision",
        "importPath": "tali_wit.frame_extractor",
        "description": "tali_wit.frame_extractor",
        "isExtraImport": true,
        "detail": "tali_wit.frame_extractor",
        "documentation": {}
    },
    {
        "label": "futures",
        "importPath": "concurrent",
        "description": "concurrent",
        "isExtraImport": true,
        "detail": "concurrent",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "ast",
        "description": "ast",
        "isExtraImport": true,
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "array",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "array",
        "description": "array",
        "detail": "array",
        "documentation": {}
    },
    {
        "label": "av",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "av",
        "description": "av",
        "detail": "av",
        "documentation": {}
    },
    {
        "label": "faulthandler",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "faulthandler",
        "description": "faulthandler",
        "detail": "faulthandler",
        "documentation": {}
    },
    {
        "label": "tali_cache_generator",
        "importPath": "tali_wit.dataset_cache_generator",
        "description": "tali_wit.dataset_cache_generator",
        "isExtraImport": true,
        "detail": "tali_wit.dataset_cache_generator",
        "documentation": {}
    },
    {
        "label": "TALICacheGenerator",
        "importPath": "tali_wit.dataset_cache_generator",
        "description": "tali_wit.dataset_cache_generator",
        "isExtraImport": true,
        "detail": "tali_wit.dataset_cache_generator",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "start",
        "importPath": "responses",
        "description": "responses",
        "isExtraImport": true,
        "detail": "responses",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "contrastive_loss",
        "importPath": "transformers.models.clip.modeling_clip",
        "description": "transformers.models.clip.modeling_clip",
        "isExtraImport": true,
        "detail": "transformers.models.clip.modeling_clip",
        "documentation": {}
    },
    {
        "label": "hydra",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hydra",
        "description": "hydra",
        "detail": "hydra",
        "documentation": {}
    },
    {
        "label": "BaseConfig",
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "isExtraImport": true,
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "collect_config_store",
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "isExtraImport": true,
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "BaseConfig",
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "isExtraImport": true,
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "collect_config_store",
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "isExtraImport": true,
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "BaseConfig",
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "isExtraImport": true,
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "collect_config_store",
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "isExtraImport": true,
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "get_max_supported_batch_size",
        "importPath": "tali_wit.ctools",
        "description": "tali_wit.ctools",
        "isExtraImport": true,
        "detail": "tali_wit.ctools",
        "documentation": {}
    },
    {
        "label": "get_max_supported_batch_size",
        "importPath": "tali_wit.ctools",
        "description": "tali_wit.ctools",
        "isExtraImport": true,
        "detail": "tali_wit.ctools",
        "documentation": {}
    },
    {
        "label": "get_max_supported_batch_size",
        "importPath": "tali_wit.ctools",
        "description": "tali_wit.ctools",
        "isExtraImport": true,
        "detail": "tali_wit.ctools",
        "documentation": {}
    },
    {
        "label": "neptune",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "neptune",
        "description": "neptune",
        "detail": "neptune",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "DictConfig",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "signal",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "signal",
        "description": "signal",
        "detail": "signal",
        "documentation": {}
    },
    {
        "label": "RichHandler",
        "importPath": "rich.logging",
        "description": "rich.logging",
        "isExtraImport": true,
        "detail": "rich.logging",
        "documentation": {}
    },
    {
        "label": "Syntax",
        "importPath": "rich.syntax",
        "description": "rich.syntax",
        "isExtraImport": true,
        "detail": "rich.syntax",
        "documentation": {}
    },
    {
        "label": "Tree",
        "importPath": "rich.tree",
        "description": "rich.tree",
        "isExtraImport": true,
        "detail": "rich.tree",
        "documentation": {}
    },
    {
        "label": "create_repo",
        "importPath": "huggingface_hub",
        "description": "huggingface_hub",
        "isExtraImport": true,
        "detail": "huggingface_hub",
        "documentation": {}
    },
    {
        "label": "hf_hub_download",
        "importPath": "huggingface_hub",
        "description": "huggingface_hub",
        "isExtraImport": true,
        "detail": "huggingface_hub",
        "documentation": {}
    },
    {
        "label": "login",
        "importPath": "huggingface_hub",
        "description": "huggingface_hub",
        "isExtraImport": true,
        "detail": "huggingface_hub",
        "documentation": {}
    },
    {
        "label": "snapshot_download",
        "importPath": "huggingface_hub",
        "description": "huggingface_hub",
        "isExtraImport": true,
        "detail": "huggingface_hub",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "orjson",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "orjson",
        "description": "orjson",
        "detail": "orjson",
        "documentation": {}
    },
    {
        "label": "torch.optim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.optim",
        "description": "torch.optim",
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "distutils.core",
        "description": "distutils.core",
        "isExtraImport": true,
        "detail": "distutils.core",
        "documentation": {}
    },
    {
        "label": "ExperimentConfig",
        "kind": 6,
        "importPath": "kubernetes.run_kube_experiments",
        "description": "kubernetes.run_kube_experiments",
        "peekOfCode": "class ExperimentConfig:\n    model: str\n    dataset: str\n    num_workers: int\n    seed: int = 42\ndef get_scripts(exp_configs: List[ExperimentConfig]):\n    script_list = []\n    for exp_config in exp_configs:\n        current_script_text = (\n            f\"/opt/conda/envs/main/bin/accelerate-launch --mixed_precision=bf16 \"",
        "detail": "kubernetes.run_kube_experiments",
        "documentation": {}
    },
    {
        "label": "get_scripts",
        "kind": 2,
        "importPath": "kubernetes.run_kube_experiments",
        "description": "kubernetes.run_kube_experiments",
        "peekOfCode": "def get_scripts(exp_configs: List[ExperimentConfig]):\n    script_list = []\n    for exp_config in exp_configs:\n        current_script_text = (\n            f\"/opt/conda/envs/main/bin/accelerate-launch --mixed_precision=bf16 \"\n            f\"/app/tali_wit/run.py exp_name=tali-2-{exp_config.model}-{exp_config.dataset}-{exp_config.seed} \"\n            f\"dataset={exp_config.dataset} model={exp_config.model} num_workers={exp_config.num_workers} seed={exp_config.seed}\"\n        )\n        script_list.append(current_script_text)\n    return script_list",
        "detail": "kubernetes.run_kube_experiments",
        "documentation": {}
    },
    {
        "label": "update_length_options",
        "kind": 2,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "def update_length_options(set_name):\n    max_idx = len(dataset_dict[set_name]) - 1\n    return gr.update(minimum=0, maximum=max_idx, step=1)\ndef get_random_sample(set_name):\n    dataset = dataset_dict[set_name]\n    sample_index = random.randint(0, len(dataset) - 1)\n    return sample_index\ndef generate_caption_output(caption_dict):\n    with gr.Column() as output:\n        for language_key, language_captions in caption_dict.items():",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "get_random_sample",
        "kind": 2,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "def get_random_sample(set_name):\n    dataset = dataset_dict[set_name]\n    sample_index = random.randint(0, len(dataset) - 1)\n    return sample_index\ndef generate_caption_output(caption_dict):\n    with gr.Column() as output:\n        for language_key, language_captions in caption_dict.items():\n            with gr.Tab(language_key):\n                for caption_key, caption in language_captions.items():\n                    gr.Textbox(value=caption, label=caption_key)",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "generate_caption_output",
        "kind": 2,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "def generate_caption_output(caption_dict):\n    with gr.Column() as output:\n        for language_key, language_captions in caption_dict.items():\n            with gr.Tab(language_key):\n                for caption_key, caption in language_captions.items():\n                    gr.Textbox(value=caption, label=caption_key)\n    return gr.update(children=[output])\ndef update_captions(language, set_name, sample_index):\n    dataset = dataset_dict[set_name]\n    sample = dataset[int(sample_index)]",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "update_captions",
        "kind": 2,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "def update_captions(language, set_name, sample_index):\n    dataset = dataset_dict[set_name]\n    sample = dataset[int(sample_index)]\n    caption_dict = sample[\"captions\"][language]\n    for key in [\n        \"caption_alt_text_description\",\n        \"caption_reference_description\",\n        \"caption_title_and_reference_description\",\n        \"context_page_description\",\n        \"context_section_description\",",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "update_language_choices",
        "kind": 2,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "def update_language_choices(set_name, sample_index):\n    # print(dataset_dict[set_name][int(sample_index)])\n    languages = list(dataset_dict[set_name][int(sample_index)][\"captions\"].keys())\n    return gr.update(choices=languages, value=languages[0]), *update_captions(\n        languages[0], set_name, sample_index\n    )\ndef load_sample(set_name, sample_index):\n    # Load the dataset based on the set name (you'll need to implement this part)\n    dataset = dataset_dict[set_name]\n    # Retrieve the sample at the given index",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "load_sample",
        "kind": 2,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "def load_sample(set_name, sample_index):\n    # Load the dataset based on the set name (you'll need to implement this part)\n    dataset = dataset_dict[set_name]\n    # Retrieve the sample at the given index\n    sample = dataset[int(sample_index)]\n    # Extract the text, image, video, and audio from the sample (you'll need to adapt this to your specific dataset)\n    subtitles = sample[\"youtube_description_text\"]\n    print(\n        f\"shapes {sample['youtube_content_video'].shape}, {sample['youtube_content_audio'].shape}, {sample['wikipedia_caption_image'].shape}, {sample['youtube_random_video_sample_image'].shape}\"\n    )",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "load_random_sample",
        "kind": 2,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "def load_random_sample(set_name):\n    sample_idx = get_random_sample(set_name)\n    return gr.update(value=sample_idx), *load_sample(set_name, sample_idx)\nif __name__ == \"__main__\":\n    callback = gr.CSVLogger()\n    with gr.Blocks(theme=gr.themes.Soft()) as demo:\n        gr.Markdown(\n            \"\"\"\n        # TALI (Temporally and semantically Aligned Audio, Language and Images) Dataset Demo v-0.3.0    \n        ## What should I expect to see here? ",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "os.environ[\"HYDRA_FULL_ERROR\"]",
        "kind": 5,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\nimport pathlib\nimport random\nimport tqdm\nfrom rich import print\nfrom rich.traceback import install\nimport datasets\nfrom tali_wit.data import ModalityTypes\ninstall()",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "os.environ[\"CUDA_VISIBLE_DEVICES\"]",
        "kind": 5,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\nimport pathlib\nimport random\nimport tqdm\nfrom rich import print\nfrom rich.traceback import install\nimport datasets\nfrom tali_wit.data import ModalityTypes\ninstall()\nfrom tali_wit.decorators import configurable",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "logger = get_logger(__name__)\nfrom tali_wit.data_plus import TALIBaseDemoTransform, TALIBaseTransformConfig\ndata_root = \"/data/datasets/tali-wit-2-1-buckets/\"\ntransform = TALIBaseDemoTransform(\n    config=TALIBaseTransformConfig(\n        root_filepath=data_root,\n        modality_list=[\n            ModalityTypes.wit_image.value,\n            ModalityTypes.wit_caption.value,\n            ModalityTypes.wit_title.value,",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "data_root",
        "kind": 5,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "data_root = \"/data/datasets/tali-wit-2-1-buckets/\"\ntransform = TALIBaseDemoTransform(\n    config=TALIBaseTransformConfig(\n        root_filepath=data_root,\n        modality_list=[\n            ModalityTypes.wit_image.value,\n            ModalityTypes.wit_caption.value,\n            ModalityTypes.wit_title.value,\n            ModalityTypes.wit_main_body.value,\n            ModalityTypes.youtube_image.value,",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "transform",
        "kind": 5,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "transform = TALIBaseDemoTransform(\n    config=TALIBaseTransformConfig(\n        root_filepath=data_root,\n        modality_list=[\n            ModalityTypes.wit_image.value,\n            ModalityTypes.wit_caption.value,\n            ModalityTypes.wit_title.value,\n            ModalityTypes.wit_main_body.value,\n            ModalityTypes.youtube_image.value,\n            ModalityTypes.youtube_video.value,",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "train_dataset",
        "kind": 5,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "train_dataset = datasets.load_from_disk(data_root + \"train-set\")\ntrain_dataset = train_dataset.with_transform(transform)\nval_dataset = datasets.load_from_disk(data_root + \"val-set\")\nval_dataset = val_dataset.with_transform(transform)\ntest_dataset = datasets.load_from_disk(data_root + \"test-set\")\ntest_dataset = test_dataset.with_transform(transform)\nnum_samples = 0\nfrom collections import defaultdict\nfrom distutils.command.upload import upload\nfrom importlib.resources import path",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "train_dataset",
        "kind": 5,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "train_dataset = train_dataset.with_transform(transform)\nval_dataset = datasets.load_from_disk(data_root + \"val-set\")\nval_dataset = val_dataset.with_transform(transform)\ntest_dataset = datasets.load_from_disk(data_root + \"test-set\")\ntest_dataset = test_dataset.with_transform(transform)\nnum_samples = 0\nfrom collections import defaultdict\nfrom distutils.command.upload import upload\nfrom importlib.resources import path\nimport gradio as gr",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "val_dataset",
        "kind": 5,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "val_dataset = datasets.load_from_disk(data_root + \"val-set\")\nval_dataset = val_dataset.with_transform(transform)\ntest_dataset = datasets.load_from_disk(data_root + \"test-set\")\ntest_dataset = test_dataset.with_transform(transform)\nnum_samples = 0\nfrom collections import defaultdict\nfrom distutils.command.upload import upload\nfrom importlib.resources import path\nimport gradio as gr\nimport torchvision",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "val_dataset",
        "kind": 5,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "val_dataset = val_dataset.with_transform(transform)\ntest_dataset = datasets.load_from_disk(data_root + \"test-set\")\ntest_dataset = test_dataset.with_transform(transform)\nnum_samples = 0\nfrom collections import defaultdict\nfrom distutils.command.upload import upload\nfrom importlib.resources import path\nimport gradio as gr\nimport torchvision\nimport torchaudio",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "test_dataset",
        "kind": 5,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "test_dataset = datasets.load_from_disk(data_root + \"test-set\")\ntest_dataset = test_dataset.with_transform(transform)\nnum_samples = 0\nfrom collections import defaultdict\nfrom distutils.command.upload import upload\nfrom importlib.resources import path\nimport gradio as gr\nimport torchvision\nimport torchaudio\ndataset_dict = {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset}",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "test_dataset",
        "kind": 5,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "test_dataset = test_dataset.with_transform(transform)\nnum_samples = 0\nfrom collections import defaultdict\nfrom distutils.command.upload import upload\nfrom importlib.resources import path\nimport gradio as gr\nimport torchvision\nimport torchaudio\ndataset_dict = {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset}\n# {",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "num_samples",
        "kind": 5,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "num_samples = 0\nfrom collections import defaultdict\nfrom distutils.command.upload import upload\nfrom importlib.resources import path\nimport gradio as gr\nimport torchvision\nimport torchaudio\ndataset_dict = {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset}\n# {\n#     'wit_idx': 502620,",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "dataset_dict",
        "kind": 5,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "dataset_dict = {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset}\n# {\n#     'wit_idx': 502620,\n#     'wikipedia_caption_image': torch.Size([3, 224, 224]),\n#     'wikipedia_text': '<section_title> Station layout </section_title>',\n#     'youtube_video_id': '6e7RO-o6u6w',\n#     'youtube_content_video': torch.Size([10, 3, 224, 224]),\n#     'youtube_content_audio': torch.Size([16000]),\n#     'youtube_description_text': \"<ysub> it's open somebody's gonna be building something there so the neighborhood\n# isn't is in change i don't think shintomicho has much of a personality when they took away the kabuki theater it",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "dataset_dict",
        "kind": 5,
        "importPath": "notebooks.dataset_demo",
        "description": "notebooks.dataset_demo",
        "peekOfCode": "dataset_dict = {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset}\ndef update_length_options(set_name):\n    max_idx = len(dataset_dict[set_name]) - 1\n    return gr.update(minimum=0, maximum=max_idx, step=1)\ndef get_random_sample(set_name):\n    dataset = dataset_dict[set_name]\n    sample_index = random.randint(0, len(dataset) - 1)\n    return sample_index\ndef generate_caption_output(caption_dict):\n    with gr.Column() as output:",
        "detail": "notebooks.dataset_demo",
        "documentation": {}
    },
    {
        "label": "AsyncGeneratorWrapper",
        "kind": 6,
        "importPath": "tali_wit.async_ops",
        "description": "tali_wit.async_ops",
        "peekOfCode": "class AsyncGeneratorWrapper:\n    def __init__(self, data_loaders: List[DataLoader]):\n        self.data_loaders = data_loaders\n        self.queue = asyncio.Queue()\n    def wrapper(self, data_loader):\n        for value in data_loader:\n            self.queue.put_nowait(value)\n        self.queue.put_nowait(None)\n    async def process_queue(self):\n        num_none_received = 0",
        "detail": "tali_wit.async_ops",
        "documentation": {}
    },
    {
        "label": "Learner",
        "kind": 6,
        "importPath": "tali_wit.boilerplate",
        "description": "tali_wit.boilerplate",
        "peekOfCode": "class Learner(nn.Module):\n    def __init__(\n        self,\n        experiment_name: str,\n        experiment_dir: Union[str, Path],\n        model: torch.nn.Module,\n        resume: Union[bool, str] = False,\n        evaluate_every_n_steps: int = None,\n        checkpoint_every_n_steps: int = None,\n        checkpoint_after_validation: bool = False,",
        "detail": "tali_wit.boilerplate",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tali_wit.boilerplate",
        "description": "tali_wit.boilerplate",
        "peekOfCode": "logger = get_logger(__name__)\n# silence logger for accelerate\naccelerate_logger = get_logger(\"accelerate\", logging_level=\"ERROR\")\n@configurable\nclass Learner(nn.Module):\n    def __init__(\n        self,\n        experiment_name: str,\n        experiment_dir: Union[str, Path],\n        model: torch.nn.Module,",
        "detail": "tali_wit.boilerplate",
        "documentation": {}
    },
    {
        "label": "accelerate_logger",
        "kind": 5,
        "importPath": "tali_wit.boilerplate",
        "description": "tali_wit.boilerplate",
        "peekOfCode": "accelerate_logger = get_logger(\"accelerate\", logging_level=\"ERROR\")\n@configurable\nclass Learner(nn.Module):\n    def __init__(\n        self,\n        experiment_name: str,\n        experiment_dir: Union[str, Path],\n        model: torch.nn.Module,\n        resume: Union[bool, str] = False,\n        evaluate_every_n_steps: int = None,",
        "detail": "tali_wit.boilerplate",
        "documentation": {}
    },
    {
        "label": "Interval",
        "kind": 6,
        "importPath": "tali_wit.callbacks",
        "description": "tali_wit.callbacks",
        "peekOfCode": "class Interval:\n    EPOCH: str = \"epoch\"\n    STEP: str = \"step\"\nclass Callback(object):\n    def __init__(self) -> None:\n        pass\n    def on_init_start(\n        self,\n        experiment: Any,\n        model: nn.Module,",
        "detail": "tali_wit.callbacks",
        "documentation": {}
    },
    {
        "label": "Callback",
        "kind": 6,
        "importPath": "tali_wit.callbacks",
        "description": "tali_wit.callbacks",
        "peekOfCode": "class Callback(object):\n    def __init__(self) -> None:\n        pass\n    def on_init_start(\n        self,\n        experiment: Any,\n        model: nn.Module,\n        train_dataloaders: DataLoader = None,\n        val_dataloaders: Union[List[DataLoader], DataLoader] = None,\n        test_dataloaders: Union[List[DataLoader], DataLoader] = None,",
        "detail": "tali_wit.callbacks",
        "documentation": {}
    },
    {
        "label": "CallbackHandler",
        "kind": 6,
        "importPath": "tali_wit.callbacks",
        "description": "tali_wit.callbacks",
        "peekOfCode": "class CallbackHandler(Callback):\n    def __init__(self, callbacks: List[Callback]) -> None:\n        super().__init__()\n        self.callbacks = callbacks\n    def on_init_start(\n        self,\n        experiment: Any,\n        model: nn.Module,\n        train_dataloaders: DataLoader = None,\n        val_dataloaders: Union[List[DataLoader], DataLoader] = None,",
        "detail": "tali_wit.callbacks",
        "documentation": {}
    },
    {
        "label": "UploadCheckpointToHuggingFaceBackground",
        "kind": 6,
        "importPath": "tali_wit.callbacks",
        "description": "tali_wit.callbacks",
        "peekOfCode": "class UploadCheckpointToHuggingFaceBackground(threading.Thread):\n    def __init__(self, repo_name: str, repo_owner: str, checkpoint_path: Path):\n        from huggingface_hub import HfApi\n        super().__init__()\n        self.repo_name = repo_name\n        self.repo_owner = repo_owner\n        self.checkpoint_path = checkpoint_path\n        self.hf_api = HfApi()\n        self.done = False\n    def run(self):",
        "detail": "tali_wit.callbacks",
        "documentation": {}
    },
    {
        "label": "UploadCheckpointsToHuggingFace",
        "kind": 6,
        "importPath": "tali_wit.callbacks",
        "description": "tali_wit.callbacks",
        "peekOfCode": "class UploadCheckpointsToHuggingFace(Callback):\n    def __init__(self, repo_name: str, repo_owner: str):\n        from huggingface_hub import HfApi\n        super().__init__()\n        self.repo_name = repo_name\n        self.repo_owner = repo_owner\n        self.hf_api = HfApi()\n    def on_save_checkpoint(\n        self,\n        model: nn.Module,",
        "detail": "tali_wit.callbacks",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tali_wit.callbacks",
        "description": "tali_wit.callbacks",
        "peekOfCode": "logger = get_logger(__name__)\nhf_logger = get_logger(\"huggingface_hub\", logging_level=logging.CRITICAL)\n@dataclass\nclass Interval:\n    EPOCH: str = \"epoch\"\n    STEP: str = \"step\"\nclass Callback(object):\n    def __init__(self) -> None:\n        pass\n    def on_init_start(",
        "detail": "tali_wit.callbacks",
        "documentation": {}
    },
    {
        "label": "hf_logger",
        "kind": 5,
        "importPath": "tali_wit.callbacks",
        "description": "tali_wit.callbacks",
        "peekOfCode": "hf_logger = get_logger(\"huggingface_hub\", logging_level=logging.CRITICAL)\n@dataclass\nclass Interval:\n    EPOCH: str = \"epoch\"\n    STEP: str = \"step\"\nclass Callback(object):\n    def __init__(self) -> None:\n        pass\n    def on_init_start(\n        self,",
        "detail": "tali_wit.callbacks",
        "documentation": {}
    },
    {
        "label": "BaseConfig",
        "kind": 6,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "class BaseConfig:\n    # Must be passed at command line -- neccesary arguments\n    exp_name: str = MISSING\n    # Defaults for these are provided in the collect_config_store method,\n    # but will be often overridden at command line\n    model: Any = MISSING\n    dataset: Any = MISSING\n    dataloader: Any = MISSING\n    optimizer: Any = MISSING\n    scheduler: Any = MISSING",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "compute_batch_size_given_gpu_memory",
        "kind": 2,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "def compute_batch_size_given_gpu_memory(reference_batch_size, gpu_memory):\n    \"\"\"Compute the batch size given the GPU memory and the reference batch size.\"\"\"\n    return int(floor(reference_batch_size * gpu_memory / 24))\n@dataclass\nclass BaseConfig:\n    # Must be passed at command line -- neccesary arguments\n    exp_name: str = MISSING\n    # Defaults for these are provided in the collect_config_store method,\n    # but will be often overridden at command line\n    model: Any = MISSING",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "collect_config_store",
        "kind": 2,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "def collect_config_store():\n    config_store = ConfigStore.instance()\n    ###################################################################################\n    tali_vit_image_text_model_config = model_config(\n        image_text_model_name=\"openai/clip-vit-base-patch16\",\n        audio_model_name=\"openai/whisper-base\",\n        multi_modality_config=MultiModalityConfig(\n            image=ModalityConfig(support=True, pretrained=True),\n            text=ModalityConfig(support=True, pretrained=True),\n            audio=ModalityConfig(support=False, pretrained=False),",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "CHECKPOINT_DIR",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "CHECKPOINT_DIR = \"${hf_cache_dir}\"\nNUM_WORKERS = \"${num_workers}\"\nHF_USERNAME = \"${hf_username}\"\nCODE_DIR = \"${code_dir}\"\nTALI_DATASET_DIR = \"${tali_dataset_dir}\"\nWIT_DATASET_DIR = \"${wit_dataset_dir}\"\nEXPERIMENT_NAME = \"${exp_name}\"\nEXPERIMENTS_ROOT_DIR = \"${root_experiment_dir}\"\nTRAIN_BATCH_SIZE = \"${train_batch_size}\"\nCURRENT_EXPERIMENT_DIR = \"${current_experiment_dir}\"",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "NUM_WORKERS",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "NUM_WORKERS = \"${num_workers}\"\nHF_USERNAME = \"${hf_username}\"\nCODE_DIR = \"${code_dir}\"\nTALI_DATASET_DIR = \"${tali_dataset_dir}\"\nWIT_DATASET_DIR = \"${wit_dataset_dir}\"\nEXPERIMENT_NAME = \"${exp_name}\"\nEXPERIMENTS_ROOT_DIR = \"${root_experiment_dir}\"\nTRAIN_BATCH_SIZE = \"${train_batch_size}\"\nCURRENT_EXPERIMENT_DIR = \"${current_experiment_dir}\"\nTRAIN_ITERS = \"${learner.train_iters}\"",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "HF_USERNAME",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "HF_USERNAME = \"${hf_username}\"\nCODE_DIR = \"${code_dir}\"\nTALI_DATASET_DIR = \"${tali_dataset_dir}\"\nWIT_DATASET_DIR = \"${wit_dataset_dir}\"\nEXPERIMENT_NAME = \"${exp_name}\"\nEXPERIMENTS_ROOT_DIR = \"${root_experiment_dir}\"\nTRAIN_BATCH_SIZE = \"${train_batch_size}\"\nCURRENT_EXPERIMENT_DIR = \"${current_experiment_dir}\"\nTRAIN_ITERS = \"${learner.train_iters}\"\nREPO_PATH = \"${repo_path}\"",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "CODE_DIR",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "CODE_DIR = \"${code_dir}\"\nTALI_DATASET_DIR = \"${tali_dataset_dir}\"\nWIT_DATASET_DIR = \"${wit_dataset_dir}\"\nEXPERIMENT_NAME = \"${exp_name}\"\nEXPERIMENTS_ROOT_DIR = \"${root_experiment_dir}\"\nTRAIN_BATCH_SIZE = \"${train_batch_size}\"\nCURRENT_EXPERIMENT_DIR = \"${current_experiment_dir}\"\nTRAIN_ITERS = \"${learner.train_iters}\"\nREPO_PATH = \"${repo_path}\"\nEXP_NAME = \"${exp_name}\"",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "TALI_DATASET_DIR",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "TALI_DATASET_DIR = \"${tali_dataset_dir}\"\nWIT_DATASET_DIR = \"${wit_dataset_dir}\"\nEXPERIMENT_NAME = \"${exp_name}\"\nEXPERIMENTS_ROOT_DIR = \"${root_experiment_dir}\"\nTRAIN_BATCH_SIZE = \"${train_batch_size}\"\nCURRENT_EXPERIMENT_DIR = \"${current_experiment_dir}\"\nTRAIN_ITERS = \"${learner.train_iters}\"\nREPO_PATH = \"${repo_path}\"\nEXP_NAME = \"${exp_name}\"\nSEED = \"${seed}\"",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "WIT_DATASET_DIR",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "WIT_DATASET_DIR = \"${wit_dataset_dir}\"\nEXPERIMENT_NAME = \"${exp_name}\"\nEXPERIMENTS_ROOT_DIR = \"${root_experiment_dir}\"\nTRAIN_BATCH_SIZE = \"${train_batch_size}\"\nCURRENT_EXPERIMENT_DIR = \"${current_experiment_dir}\"\nTRAIN_ITERS = \"${learner.train_iters}\"\nREPO_PATH = \"${repo_path}\"\nEXP_NAME = \"${exp_name}\"\nSEED = \"${seed}\"\nRESUME = \"${resume}\"",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "EXPERIMENT_NAME",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "EXPERIMENT_NAME = \"${exp_name}\"\nEXPERIMENTS_ROOT_DIR = \"${root_experiment_dir}\"\nTRAIN_BATCH_SIZE = \"${train_batch_size}\"\nCURRENT_EXPERIMENT_DIR = \"${current_experiment_dir}\"\nTRAIN_ITERS = \"${learner.train_iters}\"\nREPO_PATH = \"${repo_path}\"\nEXP_NAME = \"${exp_name}\"\nSEED = \"${seed}\"\nRESUME = \"${resume}\"\nLOGGER_LEVEL = \"${logger_level}\"",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "EXPERIMENTS_ROOT_DIR",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "EXPERIMENTS_ROOT_DIR = \"${root_experiment_dir}\"\nTRAIN_BATCH_SIZE = \"${train_batch_size}\"\nCURRENT_EXPERIMENT_DIR = \"${current_experiment_dir}\"\nTRAIN_ITERS = \"${learner.train_iters}\"\nREPO_PATH = \"${repo_path}\"\nEXP_NAME = \"${exp_name}\"\nSEED = \"${seed}\"\nRESUME = \"${resume}\"\nLOGGER_LEVEL = \"${logger_level}\"\nGPU_MEMORY = 24  # in GB",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_BATCH_SIZE",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "TRAIN_BATCH_SIZE = \"${train_batch_size}\"\nCURRENT_EXPERIMENT_DIR = \"${current_experiment_dir}\"\nTRAIN_ITERS = \"${learner.train_iters}\"\nREPO_PATH = \"${repo_path}\"\nEXP_NAME = \"${exp_name}\"\nSEED = \"${seed}\"\nRESUME = \"${resume}\"\nLOGGER_LEVEL = \"${logger_level}\"\nGPU_MEMORY = 24  # in GB\nDUMMY_BATCH_MODE = \"${dummy_batch_mode}\"",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "CURRENT_EXPERIMENT_DIR",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "CURRENT_EXPERIMENT_DIR = \"${current_experiment_dir}\"\nTRAIN_ITERS = \"${learner.train_iters}\"\nREPO_PATH = \"${repo_path}\"\nEXP_NAME = \"${exp_name}\"\nSEED = \"${seed}\"\nRESUME = \"${resume}\"\nLOGGER_LEVEL = \"${logger_level}\"\nGPU_MEMORY = 24  # in GB\nDUMMY_BATCH_MODE = \"${dummy_batch_mode}\"\nPREFETCH_FACTOR = \"${prefetch_factor}\"",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "TRAIN_ITERS",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "TRAIN_ITERS = \"${learner.train_iters}\"\nREPO_PATH = \"${repo_path}\"\nEXP_NAME = \"${exp_name}\"\nSEED = \"${seed}\"\nRESUME = \"${resume}\"\nLOGGER_LEVEL = \"${logger_level}\"\nGPU_MEMORY = 24  # in GB\nDUMMY_BATCH_MODE = \"${dummy_batch_mode}\"\nPREFETCH_FACTOR = \"${prefetch_factor}\"\nPERSISTENT_WORKERS = \"${persistent_workers}\"",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "REPO_PATH",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "REPO_PATH = \"${repo_path}\"\nEXP_NAME = \"${exp_name}\"\nSEED = \"${seed}\"\nRESUME = \"${resume}\"\nLOGGER_LEVEL = \"${logger_level}\"\nGPU_MEMORY = 24  # in GB\nDUMMY_BATCH_MODE = \"${dummy_batch_mode}\"\nPREFETCH_FACTOR = \"${prefetch_factor}\"\nPERSISTENT_WORKERS = \"${persistent_workers}\"\nPIN_MEMORY = \"${pin_memory}\"",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "EXP_NAME",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "EXP_NAME = \"${exp_name}\"\nSEED = \"${seed}\"\nRESUME = \"${resume}\"\nLOGGER_LEVEL = \"${logger_level}\"\nGPU_MEMORY = 24  # in GB\nDUMMY_BATCH_MODE = \"${dummy_batch_mode}\"\nPREFETCH_FACTOR = \"${prefetch_factor}\"\nPERSISTENT_WORKERS = \"${persistent_workers}\"\nPIN_MEMORY = \"${pin_memory}\"\nIMAGE_TEXT_MODEL_NAME = \"${model.image_text_model_name}\"",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "SEED",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "SEED = \"${seed}\"\nRESUME = \"${resume}\"\nLOGGER_LEVEL = \"${logger_level}\"\nGPU_MEMORY = 24  # in GB\nDUMMY_BATCH_MODE = \"${dummy_batch_mode}\"\nPREFETCH_FACTOR = \"${prefetch_factor}\"\nPERSISTENT_WORKERS = \"${persistent_workers}\"\nPIN_MEMORY = \"${pin_memory}\"\nIMAGE_TEXT_MODEL_NAME = \"${model.image_text_model_name}\"\nAUDIO_MODEL_NAME = \"${model.audio_model_name}\"",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "RESUME",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "RESUME = \"${resume}\"\nLOGGER_LEVEL = \"${logger_level}\"\nGPU_MEMORY = 24  # in GB\nDUMMY_BATCH_MODE = \"${dummy_batch_mode}\"\nPREFETCH_FACTOR = \"${prefetch_factor}\"\nPERSISTENT_WORKERS = \"${persistent_workers}\"\nPIN_MEMORY = \"${pin_memory}\"\nIMAGE_TEXT_MODEL_NAME = \"${model.image_text_model_name}\"\nAUDIO_MODEL_NAME = \"${model.audio_model_name}\"\nhydra_logger = get_logger(\"hydra\")",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "LOGGER_LEVEL",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "LOGGER_LEVEL = \"${logger_level}\"\nGPU_MEMORY = 24  # in GB\nDUMMY_BATCH_MODE = \"${dummy_batch_mode}\"\nPREFETCH_FACTOR = \"${prefetch_factor}\"\nPERSISTENT_WORKERS = \"${persistent_workers}\"\nPIN_MEMORY = \"${pin_memory}\"\nIMAGE_TEXT_MODEL_NAME = \"${model.image_text_model_name}\"\nAUDIO_MODEL_NAME = \"${model.audio_model_name}\"\nhydra_logger = get_logger(\"hydra\")\nHFModelUploadConfig = builds(",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "GPU_MEMORY",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "GPU_MEMORY = 24  # in GB\nDUMMY_BATCH_MODE = \"${dummy_batch_mode}\"\nPREFETCH_FACTOR = \"${prefetch_factor}\"\nPERSISTENT_WORKERS = \"${persistent_workers}\"\nPIN_MEMORY = \"${pin_memory}\"\nIMAGE_TEXT_MODEL_NAME = \"${model.image_text_model_name}\"\nAUDIO_MODEL_NAME = \"${model.audio_model_name}\"\nhydra_logger = get_logger(\"hydra\")\nHFModelUploadConfig = builds(\n    UploadCheckpointsToHuggingFace, populate_full_signature=True",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "DUMMY_BATCH_MODE",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "DUMMY_BATCH_MODE = \"${dummy_batch_mode}\"\nPREFETCH_FACTOR = \"${prefetch_factor}\"\nPERSISTENT_WORKERS = \"${persistent_workers}\"\nPIN_MEMORY = \"${pin_memory}\"\nIMAGE_TEXT_MODEL_NAME = \"${model.image_text_model_name}\"\nAUDIO_MODEL_NAME = \"${model.audio_model_name}\"\nhydra_logger = get_logger(\"hydra\")\nHFModelUploadConfig = builds(\n    UploadCheckpointsToHuggingFace, populate_full_signature=True\n)",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "PREFETCH_FACTOR",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "PREFETCH_FACTOR = \"${prefetch_factor}\"\nPERSISTENT_WORKERS = \"${persistent_workers}\"\nPIN_MEMORY = \"${pin_memory}\"\nIMAGE_TEXT_MODEL_NAME = \"${model.image_text_model_name}\"\nAUDIO_MODEL_NAME = \"${model.audio_model_name}\"\nhydra_logger = get_logger(\"hydra\")\nHFModelUploadConfig = builds(\n    UploadCheckpointsToHuggingFace, populate_full_signature=True\n)\nhf_upload = HFModelUploadConfig(repo_name=EXPERIMENT_NAME, repo_owner=HF_USERNAME)",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "PERSISTENT_WORKERS",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "PERSISTENT_WORKERS = \"${persistent_workers}\"\nPIN_MEMORY = \"${pin_memory}\"\nIMAGE_TEXT_MODEL_NAME = \"${model.image_text_model_name}\"\nAUDIO_MODEL_NAME = \"${model.audio_model_name}\"\nhydra_logger = get_logger(\"hydra\")\nHFModelUploadConfig = builds(\n    UploadCheckpointsToHuggingFace, populate_full_signature=True\n)\nhf_upload = HFModelUploadConfig(repo_name=EXPERIMENT_NAME, repo_owner=HF_USERNAME)\nadamw_optimizer_config = builds(",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "PIN_MEMORY",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "PIN_MEMORY = \"${pin_memory}\"\nIMAGE_TEXT_MODEL_NAME = \"${model.image_text_model_name}\"\nAUDIO_MODEL_NAME = \"${model.audio_model_name}\"\nhydra_logger = get_logger(\"hydra\")\nHFModelUploadConfig = builds(\n    UploadCheckpointsToHuggingFace, populate_full_signature=True\n)\nhf_upload = HFModelUploadConfig(repo_name=EXPERIMENT_NAME, repo_owner=HF_USERNAME)\nadamw_optimizer_config = builds(\n    torch.optim.AdamW,",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "IMAGE_TEXT_MODEL_NAME",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "IMAGE_TEXT_MODEL_NAME = \"${model.image_text_model_name}\"\nAUDIO_MODEL_NAME = \"${model.audio_model_name}\"\nhydra_logger = get_logger(\"hydra\")\nHFModelUploadConfig = builds(\n    UploadCheckpointsToHuggingFace, populate_full_signature=True\n)\nhf_upload = HFModelUploadConfig(repo_name=EXPERIMENT_NAME, repo_owner=HF_USERNAME)\nadamw_optimizer_config = builds(\n    torch.optim.AdamW,\n    populate_full_signature=True,",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "AUDIO_MODEL_NAME",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "AUDIO_MODEL_NAME = \"${model.audio_model_name}\"\nhydra_logger = get_logger(\"hydra\")\nHFModelUploadConfig = builds(\n    UploadCheckpointsToHuggingFace, populate_full_signature=True\n)\nhf_upload = HFModelUploadConfig(repo_name=EXPERIMENT_NAME, repo_owner=HF_USERNAME)\nadamw_optimizer_config = builds(\n    torch.optim.AdamW,\n    populate_full_signature=True,\n    zen_partial=True,",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "hydra_logger",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "hydra_logger = get_logger(\"hydra\")\nHFModelUploadConfig = builds(\n    UploadCheckpointsToHuggingFace, populate_full_signature=True\n)\nhf_upload = HFModelUploadConfig(repo_name=EXPERIMENT_NAME, repo_owner=HF_USERNAME)\nadamw_optimizer_config = builds(\n    torch.optim.AdamW,\n    populate_full_signature=True,\n    zen_partial=True,\n)",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "HFModelUploadConfig",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "HFModelUploadConfig = builds(\n    UploadCheckpointsToHuggingFace, populate_full_signature=True\n)\nhf_upload = HFModelUploadConfig(repo_name=EXPERIMENT_NAME, repo_owner=HF_USERNAME)\nadamw_optimizer_config = builds(\n    torch.optim.AdamW,\n    populate_full_signature=True,\n    zen_partial=True,\n)\ncosine_learning_rate_scheduler_config = builds(",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "hf_upload",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "hf_upload = HFModelUploadConfig(repo_name=EXPERIMENT_NAME, repo_owner=HF_USERNAME)\nadamw_optimizer_config = builds(\n    torch.optim.AdamW,\n    populate_full_signature=True,\n    zen_partial=True,\n)\ncosine_learning_rate_scheduler_config = builds(\n    CosineLRScheduler,\n    populate_full_signature=True,\n    zen_partial=True,",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "adamw_optimizer_config",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "adamw_optimizer_config = builds(\n    torch.optim.AdamW,\n    populate_full_signature=True,\n    zen_partial=True,\n)\ncosine_learning_rate_scheduler_config = builds(\n    CosineLRScheduler,\n    populate_full_signature=True,\n    zen_partial=True,\n)",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "cosine_learning_rate_scheduler_config",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "cosine_learning_rate_scheduler_config = builds(\n    CosineLRScheduler,\n    populate_full_signature=True,\n    zen_partial=True,\n)\naccelerator_config = builds(Accelerator, populate_full_signature=True)\ncosine_learning_rate_scheduler_config = cosine_learning_rate_scheduler_config()\nmodel_config = TALIModel.build_config(populate_full_signature=True)\ntali_dataset_config = TALIBase.build_config(\n    populate_full_signature=True,",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "accelerator_config",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "accelerator_config = builds(Accelerator, populate_full_signature=True)\ncosine_learning_rate_scheduler_config = cosine_learning_rate_scheduler_config()\nmodel_config = TALIModel.build_config(populate_full_signature=True)\ntali_dataset_config = TALIBase.build_config(\n    populate_full_signature=True,\n    set_name=\"train\",\n    tali_dataset_dir=TALI_DATASET_DIR,\n    modality_list=[\n        ModalityTypes.wit_image.value,\n        ModalityTypes.wit_caption.value,",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "cosine_learning_rate_scheduler_config",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "cosine_learning_rate_scheduler_config = cosine_learning_rate_scheduler_config()\nmodel_config = TALIModel.build_config(populate_full_signature=True)\ntali_dataset_config = TALIBase.build_config(\n    populate_full_signature=True,\n    set_name=\"train\",\n    tali_dataset_dir=TALI_DATASET_DIR,\n    modality_list=[\n        ModalityTypes.wit_image.value,\n        ModalityTypes.wit_caption.value,\n        ModalityTypes.wit_title.value,",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "model_config",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "model_config = TALIModel.build_config(populate_full_signature=True)\ntali_dataset_config = TALIBase.build_config(\n    populate_full_signature=True,\n    set_name=\"train\",\n    tali_dataset_dir=TALI_DATASET_DIR,\n    modality_list=[\n        ModalityTypes.wit_image.value,\n        ModalityTypes.wit_caption.value,\n        ModalityTypes.wit_title.value,\n        ModalityTypes.wit_main_body.value,",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "tali_dataset_config",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "tali_dataset_config = TALIBase.build_config(\n    populate_full_signature=True,\n    set_name=\"train\",\n    tali_dataset_dir=TALI_DATASET_DIR,\n    modality_list=[\n        ModalityTypes.wit_image.value,\n        ModalityTypes.wit_caption.value,\n        ModalityTypes.wit_title.value,\n        ModalityTypes.wit_main_body.value,\n        ModalityTypes.youtube_image.value,",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "wit_dataset_config",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "wit_dataset_config = WITBase.build_config(\n    populate_full_signature=True,\n    set_name=\"train\",\n    wit_dataset_dir=pathlib.Path(WIT_DATASET_DIR),\n    tali_dataset_dir=pathlib.Path(TALI_DATASET_DIR),\n    image_size=224,\n    num_samples_per_episode=32,\n    deterministic_sampling=False,\n    infinite_sampling=False,  # True,\n    priority_caption_language=\"en\",",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "dataloader_config",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "dataloader_config = builds(DataLoader, dataset=None, populate_full_signature=True)\nlearner_config = builds(Learner, populate_full_signature=True)\nlearner_config = learner_config(\n    model=None,\n    experiment_name=EXPERIMENT_NAME,\n    experiment_dir=CHECKPOINT_DIR,\n    resume=RESUME,\n    evaluate_every_n_steps=500,\n    checkpoint_after_validation=True,\n    checkpoint_every_n_steps=100,",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "learner_config",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "learner_config = builds(Learner, populate_full_signature=True)\nlearner_config = learner_config(\n    model=None,\n    experiment_name=EXPERIMENT_NAME,\n    experiment_dir=CHECKPOINT_DIR,\n    resume=RESUME,\n    evaluate_every_n_steps=500,\n    checkpoint_after_validation=True,\n    checkpoint_every_n_steps=100,\n    train_iters=10000,",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "learner_config",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "learner_config = learner_config(\n    model=None,\n    experiment_name=EXPERIMENT_NAME,\n    experiment_dir=CHECKPOINT_DIR,\n    resume=RESUME,\n    evaluate_every_n_steps=500,\n    checkpoint_after_validation=True,\n    checkpoint_every_n_steps=100,\n    train_iters=10000,\n    limit_val_iters=100,",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "default_callbacks",
        "kind": 5,
        "importPath": "tali_wit.config",
        "description": "tali_wit.config",
        "peekOfCode": "default_callbacks = dict(hf_uploader=hf_upload)\ndef compute_batch_size_given_gpu_memory(reference_batch_size, gpu_memory):\n    \"\"\"Compute the batch size given the GPU memory and the reference batch size.\"\"\"\n    return int(floor(reference_batch_size * gpu_memory / 24))\n@dataclass\nclass BaseConfig:\n    # Must be passed at command line -- neccesary arguments\n    exp_name: str = MISSING\n    # Defaults for these are provided in the collect_config_store method,\n    # but will be often overridden at command line",
        "detail": "tali_wit.config",
        "documentation": {}
    },
    {
        "label": "generate_hierarchical_data_dict",
        "kind": 2,
        "importPath": "tali_wit.ctools",
        "description": "tali_wit.ctools",
        "peekOfCode": "def generate_hierarchical_data_dict(data_dict: Dict[str, Any]) -> Dict[str, Any]:\n    modality_hierarchical_output_dict = {}\n    for sub_modality_name in list(data_dict.keys()):\n        modality_type = get_base_modality(sub_modality_name)\n        if modality_type is None:\n            if \"other\" not in modality_hierarchical_output_dict:\n                modality_hierarchical_output_dict[\"other\"] = {}\n            modality_hierarchical_output_dict[\"other\"][sub_modality_name] = data_dict[\n                sub_modality_name\n            ]",
        "detail": "tali_wit.ctools",
        "documentation": {}
    },
    {
        "label": "dummy_fprop_bprop",
        "kind": 2,
        "importPath": "tali_wit.ctools",
        "description": "tali_wit.ctools",
        "peekOfCode": "def dummy_fprop_bprop(\n    model: nn.Module,\n    batch: Dict[str, Any],\n    accelerator: accelerate.Accelerator,\n    do_bprop: bool = False,\n) -> None:\n    \"\"\"\n    Performs a forward and optional backward pass using the given model and batch.\n    Args:\n        model (nn.Module): The model to use for the forward and backward pass.",
        "detail": "tali_wit.ctools",
        "documentation": {}
    },
    {
        "label": "set_batch_size",
        "kind": 2,
        "importPath": "tali_wit.ctools",
        "description": "tali_wit.ctools",
        "peekOfCode": "def set_batch_size(batch: Dict[str, Any], batch_size: int) -> Dict[str, Any]:\n    \"\"\"\n    Sets the batch size for a given input batch.\n    Args:\n        batch (Dict[str, Any]): The input batch.\n        batch_size (int): The desired batch size.\n    Returns:\n        Dict[str, Any]: The input batch with the specified batch size.\n    \"\"\"\n    return {",
        "detail": "tali_wit.ctools",
        "documentation": {}
    },
    {
        "label": "get_max_supported_batch_size",
        "kind": 2,
        "importPath": "tali_wit.ctools",
        "description": "tali_wit.ctools",
        "peekOfCode": "def get_max_supported_batch_size(\n    model: nn.Module,\n    batch: Dict[str, Any],\n    accelerator: Optional[accelerate.Accelerator] = None,\n    train_mode: bool = False,\n) -> int:\n    \"\"\"\n    Finds the maximum supported batch size for the given model and batch.\n    Args:\n        model (nn.Module): The model to test.",
        "detail": "tali_wit.ctools",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tali_wit.ctools",
        "description": "tali_wit.ctools",
        "peekOfCode": "logger = get_logger(__name__)\ndef generate_hierarchical_data_dict(data_dict: Dict[str, Any]) -> Dict[str, Any]:\n    modality_hierarchical_output_dict = {}\n    for sub_modality_name in list(data_dict.keys()):\n        modality_type = get_base_modality(sub_modality_name)\n        if modality_type is None:\n            if \"other\" not in modality_hierarchical_output_dict:\n                modality_hierarchical_output_dict[\"other\"] = {}\n            modality_hierarchical_output_dict[\"other\"][sub_modality_name] = data_dict[\n                sub_modality_name",
        "detail": "tali_wit.ctools",
        "documentation": {}
    },
    {
        "label": "SplitType",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class SplitType:\n    TRAIN = \"train\"\n    VAL = \"val\"\n    TEST = \"test\"\n@dataclass\nclass MultiModalInput:\n    image: Any = None\n    audio: Any = None\n    video: Any = None\n    text: Any = None",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "MultiModalInput",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class MultiModalInput:\n    image: Any = None\n    audio: Any = None\n    video: Any = None\n    text: Any = None\ndef find_filepaths_with_extension(\n    dir_path: str, extension: str, limit_num_files: Optional[int]\n):\n    filepaths = []\n    with tqdm.tqdm(total=12000000) as pbar:",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "ChallengeSamplesSourceTypes",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class ChallengeSamplesSourceTypes:\n    WITHIN_USER: str = \"within_user\"\n    ACROSS_USERS: str = \"across_users\"\ndef rank_user_items_by_clip_score(username_filepath: pathlib.Path):\n    user_table = pq.read_table(username_filepath).to_pandas()\n    return user_table.sort_values(by=\"similarity\", ascending=False)\ndef get_ranked_filepaths_from_user(\n    username_filepath: pathlib.Path, top_k_percent_to_return: int\n):\n    ranked_user_items = rank_user_items_by_clip_score(username_filepath)",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "ToThreeChannels",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class ToThreeChannels(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, image):\n        if image.shape[0] == 1:\n            return image.repeat(3, 1, 1)\n        elif image.shape[0] == 2:\n            return torch.cat([image, image[0].unsqueeze(0)], dim=0)\n        elif image.shape[0] == 3:\n            return image",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "TALISchema",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class TALISchema:\n    wit_idx: pa.int64()\n    term_idx: pa.int64()\n    sort_type: pa.string()\n    age_restricted: pa.bool_()\n    author: pa.string()\n    channel_id: pa.string()\n    channel_url: pa.string()\n    description: pa.string()\n    embed_url: pa.string()",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "VideoCLIPScoreSchema",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class VideoCLIPScoreSchema:\n    wit_idx: pa.int32()\n    term_idx: pa.int32()\n    video_id: pa.string()\n    filepath: pa.string()\n    reference_text: pa.string()\n    scores_sorted_idx: pa.list_(pa.int32())\n    scores_sorted: pa.list_(pa.float32())\nvideo_score_schema = list(VideoCLIPScoreSchema.__dict__[\"__annotations__\"].items())\nvideo_score_schema = pa.schema(video_score_schema)",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "CrossModalityTypes",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class CrossModalityTypes:\n    image_to_text = \"image_to_text\"\n    image_to_audio = \"image_to_audio\"\n    image_to_audio = \"image_to_video\"\n    text_to_audio = \"text_to_audio\"\n    text_to_video = \"text_to_video\"\n    audio_to_video = \"audio_to_video\"\nclass BaseModalityTypes(str, Enum):\n    image = \"image\"\n    audio = \"audio\"",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "BaseModalityTypes",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class BaseModalityTypes(str, Enum):\n    image = \"image\"\n    audio = \"audio\"\n    video = \"video\"\n    text = \"text\"\nclass SubModalityTypes(str, Enum):\n    wikipedia_caption_image = \"wikipedia_caption_image\"\n    youtube_random_video_sample_image = \"youtube_random_video_sample_image\"\n    youtube_thumbnail_image = \"youtube_thumbnail_image\"\n    wikipedia_caption_text = \"wikipedia_caption_text\"",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "SubModalityTypes",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class SubModalityTypes(str, Enum):\n    wikipedia_caption_image = \"wikipedia_caption_image\"\n    youtube_random_video_sample_image = \"youtube_random_video_sample_image\"\n    youtube_thumbnail_image = \"youtube_thumbnail_image\"\n    wikipedia_caption_text = \"wikipedia_caption_text\"\n    wikipedia_title_text = \"wikipedia_title_text\"\n    wikipedia_main_body_text = \"wikipedia_main_body_text\"\n    youtube_subtitle_text = \"youtube_subtitle_text\"\n    youtube_description_text = \"youtube_description_text\"\n    youtube_title_text = \"youtube_title_text\"",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "AnyModalSample",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class AnyModalSample:\n    modality: str\n    sub_modality: str\n    shape: tuple\nclass ModalityTypes(Enum):\n    wit_image = AnyModalSample(\n        modality=BaseModalityTypes.image,\n        sub_modality=SubModalityTypes.wikipedia_caption_image,\n        shape=(\"batch_size\", \"channel\", \"height\", \"width\"),\n    )",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "ModalityTypes",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class ModalityTypes(Enum):\n    wit_image = AnyModalSample(\n        modality=BaseModalityTypes.image,\n        sub_modality=SubModalityTypes.wikipedia_caption_image,\n        shape=(\"batch_size\", \"channel\", \"height\", \"width\"),\n    )\n    youtube_image = AnyModalSample(\n        modality=BaseModalityTypes.image,\n        sub_modality=SubModalityTypes.youtube_random_video_sample_image,\n        shape=(\"batch_size\", \"channel\", \"height\", \"width\"),",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "ModalityDataSample",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class ModalityDataSample:\n    data: Any\n    modality_type: Any\ndef videoclip_to_video_audio_tensors(\n    video_path: pathlib.Path,\n    return_video: bool,\n    return_audio: bool,\n    image_size: int,\n    clip_duration_in_seconds: float,\n    rng: np.random.Generator,",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "TermIDTranslation",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class TermIDTranslation:\n    title_prompted = 0\n    caption_prompted = 1\n@dataclass\nclass WitSample:\n    wikipedia_caption_image: Any\n    wikipedia_caption_text: Any\n    wikipedia_main_body_text: Any\n    wikipedia_title_text: Any\ndef get_wit_sample(",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "WitSample",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class WitSample:\n    wikipedia_caption_image: Any\n    wikipedia_caption_text: Any\n    wikipedia_main_body_text: Any\n    wikipedia_title_text: Any\ndef get_wit_sample(\n    dataset: Any,\n    wit_index: int,\n    language_id: str = \"en\",\n    image_size: int = 224,",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "WITFeature",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class WITFeature:\n    item_idx: int\n    image: PIL.Image.Image\n    image_url: str\n    caption_alt_text_description: Optional[str] = None\n    caption_reference_description: Optional[str] = None\n    caption_title_and_reference_description: Optional[str] = None\n    context_page_description: Optional[str] = None\n    context_section_description: Optional[str] = None\n    hierarchical_section_title: Optional[str] = None",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "DefaultVideoTransforms",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class DefaultVideoTransforms:\n    def __init__(self) -> None:\n        self.processor: CLIPProcessor = CLIPProcessor.from_pretrained(\n            \"openai/clip-vit-large-patch14\"\n        )\n    def __call__(self, x) -> Any:\n        x = x.unbind(0)\n        x = self.processor(images=x, return_tensors=\"pt\")[\"pixel_values\"]\n        return x\n@configurable",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "TALIDataset",
        "kind": 6,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "class TALIDataset(torch.utils.data.Dataset):\n    def __init__(\n        self,\n        set_name: str,\n        root_filepath: Union[str, pathlib.Path],\n        modality_list: List[AnyModalSample],\n        language_id: str = \"en\",\n        rng_seed: int = 42,\n        top_k_tali: int = 10,\n        image_size: int = 224,",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "find_filepaths_with_extension",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def find_filepaths_with_extension(\n    dir_path: str, extension: str, limit_num_files: Optional[int]\n):\n    filepaths = []\n    with tqdm.tqdm(total=12000000) as pbar:\n        for path in pathlib.Path(dir_path).iterdir():\n            if path.suffix == extension and path.is_file():\n                filepaths.append(str(path))\n                if limit_num_files is not None:\n                    if len(filepaths) >= limit_num_files:",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "extract_captions_from_file",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def extract_captions_from_file(filepath: str):\n    info_dict = load_json(filepath=filepath)\n    return info_dict[\"edge_media_to_caption\"][\"edges\"][0][\"node\"][\"text\"]\ndef check_if_image_has_matching_info_file(image_path: str):\n    if isinstance(image_path, pathlib.Path):\n        image_path = str(image_path)\n    info_file_path = pathlib.Path(image_path.replace(\"image\", \"info\")).with_suffix(\n        \".info\"\n    )\n    return info_file_path.exists()",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "check_if_image_has_matching_info_file",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def check_if_image_has_matching_info_file(image_path: str):\n    if isinstance(image_path, pathlib.Path):\n        image_path = str(image_path)\n    info_file_path = pathlib.Path(image_path.replace(\"image\", \"info\")).with_suffix(\n        \".info\"\n    )\n    return info_file_path.exists()\ndef get_user_and_post_id_from_image_path(image_path: str):\n    username, post_id = image_path.split(\"/\")[-1].split(\"-\")\n    post_id = post_id.split(\".\")[0]",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "get_user_and_post_id_from_image_path",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def get_user_and_post_id_from_image_path(image_path: str):\n    username, post_id = image_path.split(\"/\")[-1].split(\"-\")\n    post_id = post_id.split(\".\")[0]\n    return username, post_id\ndef generate_post_paths_from_user_name_and_post_id(\n    username: str,\n    post_id: str,\n    post_image_dir: str,\n    post_info_dir: str,\n):",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "generate_post_paths_from_user_name_and_post_id",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def generate_post_paths_from_user_name_and_post_id(\n    username: str,\n    post_id: str,\n    post_image_dir: str,\n    post_info_dir: str,\n):\n    image_path = os.path.join(post_image_dir, f\"{username}-{post_id}.jpg\")\n    info_path = os.path.join(post_info_dir, f\"{username}-{post_id}.info\")\n    return image_path, info_path\n@dataclass",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "rank_user_items_by_clip_score",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def rank_user_items_by_clip_score(username_filepath: pathlib.Path):\n    user_table = pq.read_table(username_filepath).to_pandas()\n    return user_table.sort_values(by=\"similarity\", ascending=False)\ndef get_ranked_filepaths_from_user(\n    username_filepath: pathlib.Path, top_k_percent_to_return: int\n):\n    ranked_user_items = rank_user_items_by_clip_score(username_filepath)\n    ranked_filepath_list = ranked_user_items[\"filepath\"].tolist()\n    top_k_percent_to_return = int(\n        len(ranked_filepath_list) * top_k_percent_to_return / 100",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "get_ranked_filepaths_from_user",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def get_ranked_filepaths_from_user(\n    username_filepath: pathlib.Path, top_k_percent_to_return: int\n):\n    ranked_user_items = rank_user_items_by_clip_score(username_filepath)\n    ranked_filepath_list = ranked_user_items[\"filepath\"].tolist()\n    top_k_percent_to_return = int(\n        len(ranked_filepath_list) * top_k_percent_to_return / 100\n    )\n    return ranked_filepath_list[:top_k_percent_to_return]\nclass ToThreeChannels(nn.Module):",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "default_image_transforms",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def default_image_transforms(image_size: int = 224):\n    return Compose(\n        [\n            Resize(image_size),\n            RandomCrop(image_size),\n            ToTensor(),\n            ToThreeChannels(),\n        ]\n    )\ndefault_image_transforms_config = builds(default_image_transforms)",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "dict_to_summary",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def dict_to_summary(batch: Dict):\n    summary_dict = defaultdict(list)\n    if not isinstance(batch, dict) and not isinstance(batch, list):\n        batch = [batch.__dict__]\n    if isinstance(batch, dict):\n        batch = [batch]\n    for item in batch:\n        for key, value in item.items():\n            # print(value)\n            if hasattr(value, \"shape\"):",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "dataclass_collate",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def dataclass_collate(batch):\n    \"\"\"Collate data from a list of dataclass objects.\n    Args:\n        batch (list): List of dataclass objects.\n    Returns:\n        dict: Dictionary of values from the dataclass objects.\n    \"\"\"\n    batch = list(filter(lambda x: x is not None, batch))\n    batch = list(filter(lambda x: len(list(x.keys())) != 0, batch))\n    # for sample in batch:",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "get_image_transforms_instait",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def get_image_transforms_instait():\n    return Compose([Resize((224, 224)), ToTensor(), ToThreeChannels()])\nimport pathlib\nfrom dataclasses import dataclass\nfrom typing import List\nfrom tali_wit.data import dataclass_collate\n@dataclass\nclass TALISchema:\n    wit_idx: pa.int64()\n    term_idx: pa.int64()",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "videoclip_to_video_audio_tensors",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def videoclip_to_video_audio_tensors(\n    video_path: pathlib.Path,\n    return_video: bool,\n    return_audio: bool,\n    image_size: int,\n    clip_duration_in_seconds: float,\n    rng: np.random.Generator,\n):\n    video: EncodedVideo = EncodedVideo.from_path(video_path)\n    video_duration_in_seconds = float(video.duration)",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "get_wit_sample",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def get_wit_sample(\n    dataset: Any,\n    wit_index: int,\n    language_id: str = \"en\",\n    image_size: int = 224,\n    modality_list: List[ModalityTypes] = None,\n    if_none_return_random: bool = False,\n):\n    data_dict = get_language_specific_entries(\n        wit_idx=wit_index, wit_entry=dataset[int(wit_index)]",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "select_subtitles_between_timestamps",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def select_subtitles_between_timestamps(\n    subtitle_dict: Dict[str, str],\n    starting_timestamp: float,\n    ending_timestamp: float,\n):\n    selected_subtitles = \"\"\n    for subtitle_timestamp, subtitle_text in subtitle_dict.items():\n        subtitle_timestamp = float(subtitle_timestamp)\n        if (\n            float(subtitle_timestamp) >= starting_timestamp",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "get_base_modality",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def get_base_modality(submodality: str):\n    for item in list(ModalityTypes):\n        if item.value.sub_modality == submodality:\n            return item.value.modality\ndef get_tali_sample(\n    video_id: int,\n    modality_list: List[ModalityTypes],\n    rng_seed: int = 42,\n    root_filepath: pathlib.Path = pathlib.Path(\"/data/\"),\n    top_k: int = 10,",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "get_tali_sample",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def get_tali_sample(\n    video_id: int,\n    modality_list: List[ModalityTypes],\n    rng_seed: int = 42,\n    root_filepath: pathlib.Path = pathlib.Path(\"/data/\"),\n    top_k: int = 10,\n    image_size: int = 224,\n    clip_duration_in_seconds: float = 30,\n):\n    output_dict = {}",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "get_sample_from_wit_index",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def get_sample_from_wit_index(\n    dataset: Any,\n    wit_index: int,\n    rng_seed: int,\n    modality_list: List[ModalityTypes],\n    root_filepath: pathlib.Path = pathlib.Path(\"/data/\"),\n    top_k_wit: int = 10,\n    language_id: str = \"en\",\n    image_size: int = 224,\n    clip_duration_in_seconds: float = 30,",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "get_sample_from_video_id",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def get_sample_from_video_id(\n    dataset: Any,\n    video_id: str,\n    rng_seed: int,\n    modality_list: List[ModalityTypes],\n    root_filepath: pathlib.Path = pathlib.Path(\"/data/\"),\n    top_k_tali: int = 10,\n    language_id: str = \"en\",\n    image_size: int = 224,\n    clip_duration_in_seconds: float = 30,",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "get_language_specific_entries",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def get_language_specific_entries(\n    wit_idx: int, wit_entry: Any, language_id: List[str] = None\n):\n    if language_id is None:\n        language_id = [\"en\", \"uk\", \"fi\", \"da\", \"pl\", \"fr\"]\n    output_dict = {\n        \"image\": wit_entry[\"image\"],\n        \"image_url\": wit_entry[\"image_url\"],\n        \"item_idx\": wit_idx,\n    }",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "get_wit_sample_idx_with_video_available",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def get_wit_sample_idx_with_video_available(\n    root_path: pathlib.Path = pathlib.Path(\"/data/\"),\n):\n    wit_idx_to_tali_wit_table_path = defaultdict(list)\n    wit_to_video_paths_table_path = (\n        root_path / \"wit_to_video_paths.parquet\" / \"relevance\"\n    )\n    # /data/wit_to_video_paths.parquet/relevance/\n    with tqdm.tqdm(total=558) as top_pbar:\n        for top_level_dir in pathlib.Path(wit_to_video_paths_table_path).iterdir():",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "get_dataset_both_way_dictionaries",
        "kind": 2,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "def get_dataset_both_way_dictionaries(\n    wit_idx_with_videos_dict_filepath: Union[\n        str, pathlib.Path\n    ] = \"/data/wit_idx_with_videos_dict.json\"\n):\n    wit_idx_with_videos_dict = load_json(filepath=wit_idx_with_videos_dict_filepath)\n    video_id_to_wit_idx_dict = defaultdict(str)\n    with tqdm.tqdm(total=len(wit_idx_with_videos_dict)) as pbar:\n        for key, value in wit_idx_with_videos_dict.items():\n            for item in value:",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "logger = get_logger(__name__)\n@dataclass\nclass SplitType:\n    TRAIN = \"train\"\n    VAL = \"val\"\n    TEST = \"test\"\n@dataclass\nclass MultiModalInput:\n    image: Any = None\n    audio: Any = None",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "default_image_transforms_config",
        "kind": 5,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "default_image_transforms_config = builds(default_image_transforms)\ndef dict_to_summary(batch: Dict):\n    summary_dict = defaultdict(list)\n    if not isinstance(batch, dict) and not isinstance(batch, list):\n        batch = [batch.__dict__]\n    if isinstance(batch, dict):\n        batch = [batch]\n    for item in batch:\n        for key, value in item.items():\n            # print(value)",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "tali_schema",
        "kind": 5,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "tali_schema = list(TALISchema.__dict__[\"__annotations__\"].items())\ntali_schema = pa.schema(tali_schema)\n@dataclass\nclass VideoCLIPScoreSchema:\n    wit_idx: pa.int32()\n    term_idx: pa.int32()\n    video_id: pa.string()\n    filepath: pa.string()\n    reference_text: pa.string()\n    scores_sorted_idx: pa.list_(pa.int32())",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "tali_schema",
        "kind": 5,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "tali_schema = pa.schema(tali_schema)\n@dataclass\nclass VideoCLIPScoreSchema:\n    wit_idx: pa.int32()\n    term_idx: pa.int32()\n    video_id: pa.string()\n    filepath: pa.string()\n    reference_text: pa.string()\n    scores_sorted_idx: pa.list_(pa.int32())\n    scores_sorted: pa.list_(pa.float32())",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "video_score_schema",
        "kind": 5,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "video_score_schema = list(VideoCLIPScoreSchema.__dict__[\"__annotations__\"].items())\nvideo_score_schema = pa.schema(video_score_schema)\n@dataclass\nclass CrossModalityTypes:\n    image_to_text = \"image_to_text\"\n    image_to_audio = \"image_to_audio\"\n    image_to_audio = \"image_to_video\"\n    text_to_audio = \"text_to_audio\"\n    text_to_video = \"text_to_video\"\n    audio_to_video = \"audio_to_video\"",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "video_score_schema",
        "kind": 5,
        "importPath": "tali_wit.data",
        "description": "tali_wit.data",
        "peekOfCode": "video_score_schema = pa.schema(video_score_schema)\n@dataclass\nclass CrossModalityTypes:\n    image_to_text = \"image_to_text\"\n    image_to_audio = \"image_to_audio\"\n    image_to_audio = \"image_to_video\"\n    text_to_audio = \"text_to_audio\"\n    text_to_video = \"text_to_video\"\n    audio_to_video = \"audio_to_video\"\nclass BaseModalityTypes(str, Enum):",
        "detail": "tali_wit.data",
        "documentation": {}
    },
    {
        "label": "TALIBaseTransformConfig",
        "kind": 6,
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "peekOfCode": "class TALIBaseTransformConfig:\n    root_filepath: Union[str, pathlib.Path]\n    modality_list: List[AnyModalSample]\n    rng_seed: int = 42\n    top_k_tali: int = 10\n    image_size: int = 224\n    num_video_frames: int = 30\n    num_audio_frames: int = 44100\n    clip_duration_in_seconds: float = 3\n    deterministic_sampling: bool = False",
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "TALIBaseTransform",
        "kind": 6,
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "peekOfCode": "class TALIBaseTransform:\n    def __init__(self, config: TALIBaseTransformConfig):\n        self.config = config\n        self.modality_list = [\n            get_submodality_name(item) for item in self.config.modality_list\n        ]\n        self.image_transform = default_image_transforms(self.config.image_size)\n        self.video_transform = (\n            lambda x, start, end, rng: videoclip_to_video_audio_tensors(\n                video_path=x.replace(",
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "TALIBaseDemoTransform",
        "kind": 6,
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "peekOfCode": "class TALIBaseDemoTransform:\n    def __init__(self, config: TALIBaseTransformConfig):\n        self.config = config\n        self.modality_list = [\n            get_submodality_name(item) for item in self.config.modality_list\n        ]\n        self.image_transform = default_image_transforms(self.config.image_size)\n        self.video_transform = (\n            lambda x, start, end, rng: videoclip_to_video_audio_tensors(\n                video_path=x.replace(",
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "TALIBase",
        "kind": 6,
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "peekOfCode": "class TALIBase(Dataset):\n    def __init__(\n        self,\n        set_name: str,\n        tali_dataset_dir,\n        modality_list,\n        num_samples_per_episode: int,\n        rng_seed=42,\n        top_k_tali=10,\n        image_size=224,",
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "CustomConcatDataset",
        "kind": 6,
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "peekOfCode": "class CustomConcatDataset(Dataset):\n    def __init__(self, datasets):\n        self.datasets = datasets\n    def __len__(self):\n        return sum(len(d) for d in self.datasets)\n    def __getitem__(self, idx):\n        # logger.info(f\"dataset {idx % len(self.datasets)}, sample {idx // len(self.datasets)}\")\n        return self.datasets[idx % len(self.datasets)][idx // len(self.datasets)]\nif __name__ == \"__main__\":\n    import tqdm",
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "get_video_clip",
        "kind": 2,
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "peekOfCode": "def get_video_clip(video, starting_second, ending_second):\n    return video.get_clip(start_sec=starting_second, end_sec=ending_second)\ndef get_video_tensors(video_frames, image_size):\n    video_frames = video_frames.permute(3, 0, 1, 2).to(torch.float32)\n    video_transform = Compose(\n        [\n            ShortSideScale(size=image_size),\n            CenterCropVideo(crop_size=(image_size, image_size)),\n        ]\n    )",
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "get_video_tensors",
        "kind": 2,
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "peekOfCode": "def get_video_tensors(video_frames, image_size):\n    video_frames = video_frames.permute(3, 0, 1, 2).to(torch.float32)\n    video_transform = Compose(\n        [\n            ShortSideScale(size=image_size),\n            CenterCropVideo(crop_size=(image_size, image_size)),\n        ]\n    )\n    output_dict = ApplyTransformToKey(\"video\", video_transform)({\"video\": video_frames})\n    return output_dict[\"video\"].permute(1, 0, 2, 3) / 255.0",
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "videoclip_to_video_audio_tensors",
        "kind": 2,
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "peekOfCode": "def videoclip_to_video_audio_tensors(\n    video_path: pathlib.Path,\n    rng: np.random.Generator,\n    return_video: bool = True,\n    return_audio: bool = False,\n    return_image: bool = False,\n    image_size: int = 224,\n    starting_second: int = 0,\n    ending_second: int = None,\n    num_audio_frames: int = 1 * 16000,",
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "extract_audio",
        "kind": 2,
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "peekOfCode": "def extract_audio(num_audio_frames, audio_frames):\n    audio_duration_target = float(num_audio_frames) / 16000.0\n    source_sample_rate = 44100\n    target_sample_rate = 16000\n    audio_frames = audio_frames[: int(floor(44100 * audio_duration_target))]\n    resampler = T.Resample(\n        source_sample_rate, target_sample_rate, dtype=audio_frames.dtype\n    )\n    audio = resampler(audio_frames)\n    # audio_shape = audio.shape",
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "get_submodality_name",
        "kind": 2,
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "peekOfCode": "def get_submodality_name(item: AnyModalSample):\n    return str(item.sub_modality).replace(\"SubModalityTypes.\", \"\")\nclass TALIBaseTransform:\n    def __init__(self, config: TALIBaseTransformConfig):\n        self.config = config\n        self.modality_list = [\n            get_submodality_name(item) for item in self.config.modality_list\n        ]\n        self.image_transform = default_image_transforms(self.config.image_size)\n        self.video_transform = (",
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "generate_hierarchical_data_dict",
        "kind": 2,
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "peekOfCode": "def generate_hierarchical_data_dict(data_dict: Dict[str, Any]) -> Dict[str, Any]:\n    modality_hierarchical_output_dict = {}\n    for sub_modality_name in list(data_dict.keys()):\n        modality_type = get_base_modality(sub_modality_name)\n        if modality_type is None:\n            if \"other\" not in modality_hierarchical_output_dict:\n                modality_hierarchical_output_dict[\"other\"] = {}\n            modality_hierarchical_output_dict[\"other\"][sub_modality_name] = data_dict[\n                sub_modality_name\n            ]",
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "get_dataset",
        "kind": 2,
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "peekOfCode": "def get_dataset(\n    set_name: str,\n    tali_root_filepath,\n    hf_tali_root_filepath,\n    modality_list,\n    rng_seed=42,\n    top_k_tali=10,\n    image_size=224,\n    num_video_frames=5,\n    num_audio_frames=16000,",
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "get_next_on_error",
        "kind": 2,
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "peekOfCode": "def get_next_on_error(func: Callable) -> Callable:\n    @functools.wraps(func)\n    def wrapper_collect_metrics(*args, **kwargs):\n        try:\n            return func(*args, **kwargs)\n        except Exception as e:\n            logger.exception(\n                f\"Error occurred at idx {args} {e}, getting the next item instead.\"\n            )\n            current_time = time.time()",
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "peekOfCode": "logger = get_logger(__name__)\npytorchvideo_logger = get_logger(\"pytorchvideo\", logging_level=logging.NOTSET)\ndef get_video_clip(video, starting_second, ending_second):\n    return video.get_clip(start_sec=starting_second, end_sec=ending_second)\ndef get_video_tensors(video_frames, image_size):\n    video_frames = video_frames.permute(3, 0, 1, 2).to(torch.float32)\n    video_transform = Compose(\n        [\n            ShortSideScale(size=image_size),\n            CenterCropVideo(crop_size=(image_size, image_size)),",
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "pytorchvideo_logger",
        "kind": 5,
        "importPath": "tali_wit.data_plus",
        "description": "tali_wit.data_plus",
        "peekOfCode": "pytorchvideo_logger = get_logger(\"pytorchvideo\", logging_level=logging.NOTSET)\ndef get_video_clip(video, starting_second, ending_second):\n    return video.get_clip(start_sec=starting_second, end_sec=ending_second)\ndef get_video_tensors(video_frames, image_size):\n    video_frames = video_frames.permute(3, 0, 1, 2).to(torch.float32)\n    video_transform = Compose(\n        [\n            ShortSideScale(size=image_size),\n            CenterCropVideo(crop_size=(image_size, image_size)),\n        ]",
        "detail": "tali_wit.data_plus",
        "documentation": {}
    },
    {
        "label": "TALICacheGenerator",
        "kind": 6,
        "importPath": "tali_wit.dataset_cache_generator",
        "description": "tali_wit.dataset_cache_generator",
        "peekOfCode": "class TALICacheGenerator:\n    def __init__(\n        self,\n        set_name: str,\n        start_idx: int,\n        end_idx: int,\n        root_path=\"/data/datasets/tali-wit-2-1-buckets/\",\n        num_workers=8,\n    ):\n        self.num_workers = num_workers",
        "detail": "tali_wit.dataset_cache_generator",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tali_wit.dataset_cache_generator",
        "description": "tali_wit.dataset_cache_generator",
        "peekOfCode": "logger = get_logger(__name__)\nimport torch\nclass TALICacheGenerator:\n    def __init__(\n        self,\n        set_name: str,\n        start_idx: int,\n        end_idx: int,\n        root_path=\"/data/datasets/tali-wit-2-1-buckets/\",\n        num_workers=8,",
        "detail": "tali_wit.dataset_cache_generator",
        "documentation": {}
    },
    {
        "label": "configurable",
        "kind": 2,
        "importPath": "tali_wit.decorators",
        "description": "tali_wit.decorators",
        "peekOfCode": "def configurable(func: Callable) -> Callable:\n    func.__configurable__ = True\n    def build_config(**kwargs):\n        return builds(func, **kwargs)\n    setattr(func, \"build_config\", build_config)\n    return func\ndef check_if_configurable(func: Callable, phase_name: str) -> bool:\n    return func.__configurable__ if hasattr(func, \"__configurable__\") else False\ndef collect_metrics(func: Callable) -> Callable:\n    def collect_metrics(",
        "detail": "tali_wit.decorators",
        "documentation": {}
    },
    {
        "label": "check_if_configurable",
        "kind": 2,
        "importPath": "tali_wit.decorators",
        "description": "tali_wit.decorators",
        "peekOfCode": "def check_if_configurable(func: Callable, phase_name: str) -> bool:\n    return func.__configurable__ if hasattr(func, \"__configurable__\") else False\ndef collect_metrics(func: Callable) -> Callable:\n    def collect_metrics(\n        metrics_dict: dict(),\n        phase_name: str,\n        experiment_tracker: Any,\n    ) -> None:\n        for metric_key, computed_value in metrics_dict.items():\n            if computed_value is not None:",
        "detail": "tali_wit.decorators",
        "documentation": {}
    },
    {
        "label": "collect_metrics",
        "kind": 2,
        "importPath": "tali_wit.decorators",
        "description": "tali_wit.decorators",
        "peekOfCode": "def collect_metrics(func: Callable) -> Callable:\n    def collect_metrics(\n        metrics_dict: dict(),\n        phase_name: str,\n        experiment_tracker: Any,\n    ) -> None:\n        for metric_key, computed_value in metrics_dict.items():\n            if computed_value is not None:\n                value = (\n                    computed_value.detach().item()",
        "detail": "tali_wit.decorators",
        "documentation": {}
    },
    {
        "label": "Evaluator",
        "kind": 6,
        "importPath": "tali_wit.evaluators",
        "description": "tali_wit.evaluators",
        "peekOfCode": "class Evaluator(object):\n    def __init__(self):\n        pass\n@dataclass\nclass EvaluatorOutput:\n    global_step: int\n    metrics: Dict\n    phase_name: str\n    experiment_tracker: Any = None\nclass ClassificationEvaluator(Evaluator):",
        "detail": "tali_wit.evaluators",
        "documentation": {}
    },
    {
        "label": "EvaluatorOutput",
        "kind": 6,
        "importPath": "tali_wit.evaluators",
        "description": "tali_wit.evaluators",
        "peekOfCode": "class EvaluatorOutput:\n    global_step: int\n    metrics: Dict\n    phase_name: str\n    experiment_tracker: Any = None\nclass ClassificationEvaluator(Evaluator):\n    def __init__(self, experiment_tracker: Any):\n        super().__init__()\n        self.state_dict = {}\n        self.experiment_tracker = experiment_tracker",
        "detail": "tali_wit.evaluators",
        "documentation": {}
    },
    {
        "label": "ClassificationEvaluator",
        "kind": 6,
        "importPath": "tali_wit.evaluators",
        "description": "tali_wit.evaluators",
        "peekOfCode": "class ClassificationEvaluator(Evaluator):\n    def __init__(self, experiment_tracker: Any):\n        super().__init__()\n        self.state_dict = {}\n        self.experiment_tracker = experiment_tracker\n    def validation_step(\n        self,\n        model,\n        batch,\n        global_step,",
        "detail": "tali_wit.evaluators",
        "documentation": {}
    },
    {
        "label": "get_dict_shapes",
        "kind": 2,
        "importPath": "tali_wit.evaluators",
        "description": "tali_wit.evaluators",
        "peekOfCode": "def get_dict_shapes(x):\n    return (\n        {\n            key: value.shape if isinstance(value, torch.Tensor) else len(value)\n            for key, value in x.items()\n        }\n        if isinstance(x, dict)\n        else get_dict_shapes(x.__dict__)\n    )\nclass Evaluator(object):",
        "detail": "tali_wit.evaluators",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tali_wit.evaluators",
        "description": "tali_wit.evaluators",
        "peekOfCode": "logger = get_logger(__name__)\ndef get_dict_shapes(x):\n    return (\n        {\n            key: value.shape if isinstance(value, torch.Tensor) else len(value)\n            for key, value in x.items()\n        }\n        if isinstance(x, dict)\n        else get_dict_shapes(x.__dict__)\n    )",
        "detail": "tali_wit.evaluators",
        "documentation": {}
    },
    {
        "label": "FrameSelectionMethod",
        "kind": 6,
        "importPath": "tali_wit.frame_extractor",
        "description": "tali_wit.frame_extractor",
        "peekOfCode": "class FrameSelectionMethod:\n    \"\"\"\n    Enum-like class for frame selection methods \n    \"\"\"\n    RANDOM: str = \"random\"  # \n    UNIFORM: str = \"uniform\"  # \n    SEQUENTIAL: str = \"sequential\"  # \nimport faulthandler\nfaulthandler.enable()\ndef extract_frames_torchvision(",
        "detail": "tali_wit.frame_extractor",
        "documentation": {}
    },
    {
        "label": "extract_frames_torchvision",
        "kind": 2,
        "importPath": "tali_wit.frame_extractor",
        "description": "tali_wit.frame_extractor",
        "peekOfCode": "def extract_frames_torchvision(\n    video_path: str,\n    modality: str,\n    starting_second: float,\n    ending_second: float,\n    num_frames: int,\n    rng: np.random.Generator,\n    frame_selection_method: str = FrameSelectionMethod.RANDOM,\n) -> torch.Tensor:\n    \"\"\"",
        "detail": "tali_wit.frame_extractor",
        "documentation": {}
    },
    {
        "label": "seek_to_second",
        "kind": 2,
        "importPath": "tali_wit.frame_extractor",
        "description": "tali_wit.frame_extractor",
        "peekOfCode": "def seek_to_second(container, stream, second):\n    # Convert the second to the stream's time base\n    timestamp = int(second * stream.time_base.denominator / stream.time_base.numerator)\n    # Seek to the timestamp\n    container.seek(timestamp, stream=stream)\n    return container\ndef duration_in_seconds(stream):\n    return float(stream.duration * stream.time_base)\ndef frame_timestamp_in_seconds(frame, stream):\n    return float(frame.pts * stream.time_base)",
        "detail": "tali_wit.frame_extractor",
        "documentation": {}
    },
    {
        "label": "duration_in_seconds",
        "kind": 2,
        "importPath": "tali_wit.frame_extractor",
        "description": "tali_wit.frame_extractor",
        "peekOfCode": "def duration_in_seconds(stream):\n    return float(stream.duration * stream.time_base)\ndef frame_timestamp_in_seconds(frame, stream):\n    return float(frame.pts * stream.time_base)\ndef duration_in_seconds_from_path(video_path, modality):\n    with av.open(video_path) as container:\n        stream = next(s for s in container.streams if s.type == modality)\n        return duration_in_seconds(stream)\n# # Open the video file\n# input_file = \"path/to/your/video/file.mp4\"",
        "detail": "tali_wit.frame_extractor",
        "documentation": {}
    },
    {
        "label": "frame_timestamp_in_seconds",
        "kind": 2,
        "importPath": "tali_wit.frame_extractor",
        "description": "tali_wit.frame_extractor",
        "peekOfCode": "def frame_timestamp_in_seconds(frame, stream):\n    return float(frame.pts * stream.time_base)\ndef duration_in_seconds_from_path(video_path, modality):\n    with av.open(video_path) as container:\n        stream = next(s for s in container.streams if s.type == modality)\n        return duration_in_seconds(stream)\n# # Open the video file\n# input_file = \"path/to/your/video/file.mp4\"\n# container = av.open(input_file)\n# # Get the video stream",
        "detail": "tali_wit.frame_extractor",
        "documentation": {}
    },
    {
        "label": "duration_in_seconds_from_path",
        "kind": 2,
        "importPath": "tali_wit.frame_extractor",
        "description": "tali_wit.frame_extractor",
        "peekOfCode": "def duration_in_seconds_from_path(video_path, modality):\n    with av.open(video_path) as container:\n        stream = next(s for s in container.streams if s.type == modality)\n        return duration_in_seconds(stream)\n# # Open the video file\n# input_file = \"path/to/your/video/file.mp4\"\n# container = av.open(input_file)\n# # Get the video stream\n# video_stream = next(s for s in container.streams if s.type == 'video')\ndef extract_frames_pyav(",
        "detail": "tali_wit.frame_extractor",
        "documentation": {}
    },
    {
        "label": "extract_frames_pyav",
        "kind": 2,
        "importPath": "tali_wit.frame_extractor",
        "description": "tali_wit.frame_extractor",
        "peekOfCode": "def extract_frames_pyav(\n    video_path: str,\n    modality: str,\n    starting_second: float,\n    ending_second: float,\n    num_frames: int,\n    rng: np.random.Generator,\n    frame_selection_method: str = FrameSelectionMethod.RANDOM,\n    key_frames_only: bool = False,\n    stereo_audio_if_available: bool = False,",
        "detail": "tali_wit.frame_extractor",
        "documentation": {}
    },
    {
        "label": "test_extract_frames_torchvision",
        "kind": 2,
        "importPath": "tali_wit.frame_extractor",
        "description": "tali_wit.frame_extractor",
        "peekOfCode": "def test_extract_frames_torchvision():\n    \"\"\"\n    Test function for extract_frames \n    \"\"\"\n    video_path = \"/data/datasets/tali-wit-2-1-buckets/video_data.parquet/550/550321/4chLRYT8ylY/360p_90.mp4\"\n    # video_path = \"/data/datasets/tali-wit-2-1-buckets//video_data.parquet/10/10586/SA7bKo4HRTg/360p_0.mp4\"\n    modality = \"video\"\n    start_time = 10\n    end_time = 20\n    num_frames = 30",
        "detail": "tali_wit.frame_extractor",
        "documentation": {}
    },
    {
        "label": "test_extract_frames_video_pyav",
        "kind": 2,
        "importPath": "tali_wit.frame_extractor",
        "description": "tali_wit.frame_extractor",
        "peekOfCode": "def test_extract_frames_video_pyav():\n    video_path = \"/data/datasets/tali-wit-2-1-buckets/video_data.parquet/550/550321/4chLRYT8ylY/360p_90.mp4\"\n    video_path = \"/data/datasets/tali-wit-2-1-buckets//video_data.parquet/10/10586/SA7bKo4HRTg/360p_0.mp4\"\n    modality = \"video\"\n    start_time = 10\n    end_time = 20\n    num_frames = 30\n    rng = np.random.default_rng()\n    for selection_method in [\n        FrameSelectionMethod.RANDOM,",
        "detail": "tali_wit.frame_extractor",
        "documentation": {}
    },
    {
        "label": "test_extract_frames_audio_pyav",
        "kind": 2,
        "importPath": "tali_wit.frame_extractor",
        "description": "tali_wit.frame_extractor",
        "peekOfCode": "def test_extract_frames_audio_pyav():\n    video_path = \"/data/datasets/tali-wit-2-1-buckets/video_data.parquet/550/550321/4chLRYT8ylY/360p_90.mp4\"\n    video_path = \"/data/datasets/tali-wit-2-1-buckets//video_data.parquet/10/10586/SA7bKo4HRTg/360p_0.mp4\"\n    modality = \"audio\"\n    start_time = 10\n    end_time = 20\n    num_frames = 88200\n    rng = np.random.default_rng()\n    for selection_method in [\n        FrameSelectionMethod.RANDOM,",
        "detail": "tali_wit.frame_extractor",
        "documentation": {}
    },
    {
        "label": "#logger",
        "kind": 5,
        "importPath": "tali_wit.frame_extractor",
        "description": "tali_wit.frame_extractor",
        "peekOfCode": "#logger = get_#logger(name=__name__)\nclass FrameSelectionMethod:\n    \"\"\"\n    Enum-like class for frame selection methods \n    \"\"\"\n    RANDOM: str = \"random\"  # \n    UNIFORM: str = \"uniform\"  # \n    SEQUENTIAL: str = \"sequential\"  # \nimport faulthandler\nfaulthandler.enable()",
        "detail": "tali_wit.frame_extractor",
        "documentation": {}
    },
    {
        "label": "train_tali_generator",
        "kind": 2,
        "importPath": "tali_wit.generate_dataset",
        "description": "tali_wit.generate_dataset",
        "peekOfCode": "def train_tali_generator():\n    return tali_cache_generator(set_name=\"train\")\ndef val_tali_generator():\n    return tali_cache_generator(set_name=\"val\")\ndef test_tali_generator():\n    return tali_cache_generator(set_name=\"test\")\nds = Dataset.from_generator(val_tali_generator, cache_dir=\"/devcode/tali-2-2/val/cache\")\nds.save_to_disk(\"/devcode/tali-2-2/val-set\")\nds = Dataset.from_generator(\n    test_tali_generator, cache_dir=\"/devcode/tali-2-2/test/cache\"",
        "detail": "tali_wit.generate_dataset",
        "documentation": {}
    },
    {
        "label": "val_tali_generator",
        "kind": 2,
        "importPath": "tali_wit.generate_dataset",
        "description": "tali_wit.generate_dataset",
        "peekOfCode": "def val_tali_generator():\n    return tali_cache_generator(set_name=\"val\")\ndef test_tali_generator():\n    return tali_cache_generator(set_name=\"test\")\nds = Dataset.from_generator(val_tali_generator, cache_dir=\"/devcode/tali-2-2/val/cache\")\nds.save_to_disk(\"/devcode/tali-2-2/val-set\")\nds = Dataset.from_generator(\n    test_tali_generator, cache_dir=\"/devcode/tali-2-2/test/cache\"\n)\nds.save_to_disk(\"/devcode/tali-2-2/test-set\")",
        "detail": "tali_wit.generate_dataset",
        "documentation": {}
    },
    {
        "label": "test_tali_generator",
        "kind": 2,
        "importPath": "tali_wit.generate_dataset",
        "description": "tali_wit.generate_dataset",
        "peekOfCode": "def test_tali_generator():\n    return tali_cache_generator(set_name=\"test\")\nds = Dataset.from_generator(val_tali_generator, cache_dir=\"/devcode/tali-2-2/val/cache\")\nds.save_to_disk(\"/devcode/tali-2-2/val-set\")\nds = Dataset.from_generator(\n    test_tali_generator, cache_dir=\"/devcode/tali-2-2/test/cache\"\n)\nds.save_to_disk(\"/devcode/tali-2-2/test-set\")\n# ds = Dataset.from_generator(\n#     train_tali_generator, cache_dir=\"/devcode/tali-2-2/train/cache\"",
        "detail": "tali_wit.generate_dataset",
        "documentation": {}
    },
    {
        "label": "ds",
        "kind": 5,
        "importPath": "tali_wit.generate_dataset",
        "description": "tali_wit.generate_dataset",
        "peekOfCode": "ds = Dataset.from_generator(val_tali_generator, cache_dir=\"/devcode/tali-2-2/val/cache\")\nds.save_to_disk(\"/devcode/tali-2-2/val-set\")\nds = Dataset.from_generator(\n    test_tali_generator, cache_dir=\"/devcode/tali-2-2/test/cache\"\n)\nds.save_to_disk(\"/devcode/tali-2-2/test-set\")\n# ds = Dataset.from_generator(\n#     train_tali_generator, cache_dir=\"/devcode/tali-2-2/train/cache\"\n# )\n# ds.save_to_disk(\"/devcode/tali-2-2/train-set\")",
        "detail": "tali_wit.generate_dataset",
        "documentation": {}
    },
    {
        "label": "ds",
        "kind": 5,
        "importPath": "tali_wit.generate_dataset",
        "description": "tali_wit.generate_dataset",
        "peekOfCode": "ds = Dataset.from_generator(\n    test_tali_generator, cache_dir=\"/devcode/tali-2-2/test/cache\"\n)\nds.save_to_disk(\"/devcode/tali-2-2/test-set\")\n# ds = Dataset.from_generator(\n#     train_tali_generator, cache_dir=\"/devcode/tali-2-2/train/cache\"\n# )\n# ds.save_to_disk(\"/devcode/tali-2-2/train-set\")",
        "detail": "tali_wit.generate_dataset",
        "documentation": {}
    },
    {
        "label": "empty_tmp_dirs",
        "kind": 2,
        "importPath": "tali_wit.generate_hf_cache_dataset",
        "description": "tali_wit.generate_hf_cache_dataset",
        "peekOfCode": "def empty_tmp_dirs():\n    tmp_dir = tempfile.gettempdir()\n    # Iterate through the contents of the temporary directory\n    for entry in os.listdir(tmp_dir):\n        entry_path = os.path.join(tmp_dir, entry)\n        # Remove files and directories\n        try:\n            if os.path.isfile(entry_path):\n                os.remove(entry_path)\n            elif os.path.isdir(entry_path):",
        "detail": "tali_wit.generate_hf_cache_dataset",
        "documentation": {}
    },
    {
        "label": "os.environ[\"FFREPORT\"]",
        "kind": 5,
        "importPath": "tali_wit.generate_hf_cache_dataset",
        "description": "tali_wit.generate_hf_cache_dataset",
        "peekOfCode": "os.environ[\"FFREPORT\"] = \"loglevel=error\"\nos.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \"loglevel;error\"\n# null_device = open(os.devnull, 'w')\n# sys.stderr = null_device\nimport pathlib\nimport shutil\nimport datasets\nfrom tali_wit.dataset_cache_generator import TALICacheGenerator\nfrom rich import print\nfrom rich.traceback import install",
        "detail": "tali_wit.generate_hf_cache_dataset",
        "documentation": {}
    },
    {
        "label": "os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"]",
        "kind": 5,
        "importPath": "tali_wit.generate_hf_cache_dataset",
        "description": "tali_wit.generate_hf_cache_dataset",
        "peekOfCode": "os.environ[\"OPENCV_FFMPEG_CAPTURE_OPTIONS\"] = \"loglevel;error\"\n# null_device = open(os.devnull, 'w')\n# sys.stderr = null_device\nimport pathlib\nimport shutil\nimport datasets\nfrom tali_wit.dataset_cache_generator import TALICacheGenerator\nfrom rich import print\nfrom rich.traceback import install\nimport os",
        "detail": "tali_wit.generate_hf_cache_dataset",
        "documentation": {}
    },
    {
        "label": "local_path",
        "kind": 5,
        "importPath": "tali_wit.generate_hf_cache_dataset",
        "description": "tali_wit.generate_hf_cache_dataset",
        "peekOfCode": "local_path = \"/data/datasets/tali-wit-2-1-buckets/\"\nremote_path = \"/data/\"\nremote_path = \"/home/jupyter/\"\ncurrent_path = remote_path\ndef empty_tmp_dirs():\n    tmp_dir = tempfile.gettempdir()\n    # Iterate through the contents of the temporary directory\n    for entry in os.listdir(tmp_dir):\n        entry_path = os.path.join(tmp_dir, entry)\n        # Remove files and directories",
        "detail": "tali_wit.generate_hf_cache_dataset",
        "documentation": {}
    },
    {
        "label": "remote_path",
        "kind": 5,
        "importPath": "tali_wit.generate_hf_cache_dataset",
        "description": "tali_wit.generate_hf_cache_dataset",
        "peekOfCode": "remote_path = \"/data/\"\nremote_path = \"/home/jupyter/\"\ncurrent_path = remote_path\ndef empty_tmp_dirs():\n    tmp_dir = tempfile.gettempdir()\n    # Iterate through the contents of the temporary directory\n    for entry in os.listdir(tmp_dir):\n        entry_path = os.path.join(tmp_dir, entry)\n        # Remove files and directories\n        try:",
        "detail": "tali_wit.generate_hf_cache_dataset",
        "documentation": {}
    },
    {
        "label": "remote_path",
        "kind": 5,
        "importPath": "tali_wit.generate_hf_cache_dataset",
        "description": "tali_wit.generate_hf_cache_dataset",
        "peekOfCode": "remote_path = \"/home/jupyter/\"\ncurrent_path = remote_path\ndef empty_tmp_dirs():\n    tmp_dir = tempfile.gettempdir()\n    # Iterate through the contents of the temporary directory\n    for entry in os.listdir(tmp_dir):\n        entry_path = os.path.join(tmp_dir, entry)\n        # Remove files and directories\n        try:\n            if os.path.isfile(entry_path):",
        "detail": "tali_wit.generate_hf_cache_dataset",
        "documentation": {}
    },
    {
        "label": "current_path",
        "kind": 5,
        "importPath": "tali_wit.generate_hf_cache_dataset",
        "description": "tali_wit.generate_hf_cache_dataset",
        "peekOfCode": "current_path = remote_path\ndef empty_tmp_dirs():\n    tmp_dir = tempfile.gettempdir()\n    # Iterate through the contents of the temporary directory\n    for entry in os.listdir(tmp_dir):\n        entry_path = os.path.join(tmp_dir, entry)\n        # Remove files and directories\n        try:\n            if os.path.isfile(entry_path):\n                os.remove(entry_path)",
        "detail": "tali_wit.generate_hf_cache_dataset",
        "documentation": {}
    },
    {
        "label": "ModelAndTransform",
        "kind": 6,
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "peekOfCode": "class ModelAndTransform:\n    model: nn.Module\n    transform: Any\n@dataclass\nclass ModalityConfig:\n    support: bool = False\n    pretrained: bool = False\n@dataclass\nclass MultiModalityConfig:\n    image: ModalityConfig = ModalityConfig(support=True, pretrained=True)",
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "ModalityConfig",
        "kind": 6,
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "peekOfCode": "class ModalityConfig:\n    support: bool = False\n    pretrained: bool = False\n@dataclass\nclass MultiModalityConfig:\n    image: ModalityConfig = ModalityConfig(support=True, pretrained=True)\n    text: ModalityConfig = ModalityConfig(support=True, pretrained=True)\n    audio: ModalityConfig = ModalityConfig(support=True, pretrained=True)\n    video: ModalityConfig = ModalityConfig(support=True, pretrained=True)\ndef contrastive_accuracy(logits):",
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "MultiModalityConfig",
        "kind": 6,
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "peekOfCode": "class MultiModalityConfig:\n    image: ModalityConfig = ModalityConfig(support=True, pretrained=True)\n    text: ModalityConfig = ModalityConfig(support=True, pretrained=True)\n    audio: ModalityConfig = ModalityConfig(support=True, pretrained=True)\n    video: ModalityConfig = ModalityConfig(support=True, pretrained=True)\ndef contrastive_accuracy(logits):\n    targets = torch.arange(logits.shape[0]).to(logits.device)\n    return (logits.argmax(dim=-1) == targets).float().mean()\ndef contrastive_accuracy_top_k(logits, k: int = 5):\n    targets = torch.arange(logits.shape[0]).to(logits.device)",
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "PositionalEncoding",
        "kind": 6,
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "peekOfCode": "class PositionalEncoding(nn.Module):\n    def __init__(\n        self,\n    ):\n        super().__init__()\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Args:\n            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n        \"\"\"",
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "VideoTransformer",
        "kind": 6,
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "peekOfCode": "class VideoTransformer(nn.Module):\n    def __init__(\n        self,\n        d_model: int,\n        nhead: int,\n        dim_feedforward: int,\n        dropout: float,\n        num_layers: int,\n        batch_first: bool = True,\n        norm_first: bool = True,",
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "TALIModel",
        "kind": 6,
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "peekOfCode": "class TALIModel(nn.Module):\n    def __init__(\n        self,\n        image_text_model_name: str = \"openai/clip-vit-large-patch14\",\n        audio_model_name: str = \"openai/whisper-small\",\n        multi_modality_config: MultiModalityConfig = MultiModalityConfig(),\n    ):\n        super().__init__()\n        self.image_text_model_name = image_text_model_name\n        self.audio_model_name = audio_model_name",
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "contrastive_accuracy",
        "kind": 2,
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "peekOfCode": "def contrastive_accuracy(logits):\n    targets = torch.arange(logits.shape[0]).to(logits.device)\n    return (logits.argmax(dim=-1) == targets).float().mean()\ndef contrastive_accuracy_top_k(logits, k: int = 5):\n    targets = torch.arange(logits.shape[0]).to(logits.device)\n    accuracy = [\n        any(logit.argsort(dim=-1, descending=True)[:k] == target)\n        for logit, target in zip(logits, targets)\n    ]\n    return torch.mean(torch.tensor(accuracy).float())",
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "contrastive_accuracy_top_k",
        "kind": 2,
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "peekOfCode": "def contrastive_accuracy_top_k(logits, k: int = 5):\n    targets = torch.arange(logits.shape[0]).to(logits.device)\n    accuracy = [\n        any(logit.argsort(dim=-1, descending=True)[:k] == target)\n        for logit, target in zip(logits, targets)\n    ]\n    return torch.mean(torch.tensor(accuracy).float())\ndef num_parameters(\n    model, only_trainable: bool = False, exclude_embeddings: bool = False\n) -> int:",
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "num_parameters",
        "kind": 2,
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "peekOfCode": "def num_parameters(\n    model, only_trainable: bool = False, exclude_embeddings: bool = False\n) -> int:\n    \"\"\"\n    Get number of (optionally, trainable or non-embeddings) parameters in the module.\n    Args:\n        only_trainable (`bool`, *optional*, defaults to `False`):\n            Whether or not to return only the number of trainable parameters\n        exclude_embeddings (`bool`, *optional*, defaults to `False`):\n            Whether or not to return only the number of non-embeddings parameters",
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "get_device",
        "kind": 2,
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "peekOfCode": "def get_device():\n    return torch.cuda.current_device() if torch.cuda.is_available() else \"cpu\"\ndef get_similarities(\n    modality_a_name: str,\n    modality_b_name: str,\n    tensor_modality_a: torch.Tensor,\n    tensor_modality_b: torch.Tensor,\n    logit_scale: torch.Tensor,\n    return_loss: bool = False,\n) -> torch.Tensor:",
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "get_similarities",
        "kind": 2,
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "peekOfCode": "def get_similarities(\n    modality_a_name: str,\n    modality_b_name: str,\n    tensor_modality_a: torch.Tensor,\n    tensor_modality_b: torch.Tensor,\n    logit_scale: torch.Tensor,\n    return_loss: bool = False,\n) -> torch.Tensor:\n    \"\"\"\n    Args:",
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "extract_all_possible_pairs",
        "kind": 2,
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "peekOfCode": "def extract_all_possible_pairs(batch_dict):\n    from itertools import combinations\n    modality_dict = {}\n    for key, value in batch_dict.items():\n        if isinstance(value, dict) and key != \"other\":\n            modality_dict[key] = list(value.keys())\n    pairs_keys = combinations(list(modality_dict.keys()), 2)\n    # get all possible pairs of two lists\n    pairs = []\n    for key1, key2 in pairs_keys:",
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tali_wit.models",
        "description": "tali_wit.models",
        "peekOfCode": "logger = get_logger(__name__)\n@dataclass\nclass ModelAndTransform:\n    model: nn.Module\n    transform: Any\n@dataclass\nclass ModalityConfig:\n    support: bool = False\n    pretrained: bool = False\n@dataclass",
        "detail": "tali_wit.models",
        "documentation": {}
    },
    {
        "label": "test",
        "kind": 2,
        "importPath": "tali_wit.models_test",
        "description": "tali_wit.models_test",
        "peekOfCode": "def test(cfg: BaseConfig) -> None:\n    print(pretty_config(cfg, resolve=True))\n    set_seed(seed=cfg.seed)\n    model: TALIModel = instantiate(cfg.model)\n    for dataset_name, (batch_size, dataset) in cfg.dataset.items():\n        logger.info(f\"Setting up {dataset_name} train dataset\")\n        train_dataset = instantiate(\n            dataset, set_name=\"train\", infinite_sampling=True\n        )\n        logger.info(f\"Setting up {dataset_name} train dataloader\")",
        "detail": "tali_wit.models_test",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tali_wit.models_test",
        "description": "tali_wit.models_test",
        "peekOfCode": "logger = get_logger(name=__name__)\nconfig_store = collect_config_store()\n@hydra.main(config_path=None, config_name=\"config\", version_base=None)\ndef test(cfg: BaseConfig) -> None:\n    print(pretty_config(cfg, resolve=True))\n    set_seed(seed=cfg.seed)\n    model: TALIModel = instantiate(cfg.model)\n    for dataset_name, (batch_size, dataset) in cfg.dataset.items():\n        logger.info(f\"Setting up {dataset_name} train dataset\")\n        train_dataset = instantiate(",
        "detail": "tali_wit.models_test",
        "documentation": {}
    },
    {
        "label": "config_store",
        "kind": 5,
        "importPath": "tali_wit.models_test",
        "description": "tali_wit.models_test",
        "peekOfCode": "config_store = collect_config_store()\n@hydra.main(config_path=None, config_name=\"config\", version_base=None)\ndef test(cfg: BaseConfig) -> None:\n    print(pretty_config(cfg, resolve=True))\n    set_seed(seed=cfg.seed)\n    model: TALIModel = instantiate(cfg.model)\n    for dataset_name, (batch_size, dataset) in cfg.dataset.items():\n        logger.info(f\"Setting up {dataset_name} train dataset\")\n        train_dataset = instantiate(\n            dataset, set_name=\"train\", infinite_sampling=True",
        "detail": "tali_wit.models_test",
        "documentation": {}
    },
    {
        "label": "instantiate_callbacks",
        "kind": 2,
        "importPath": "tali_wit.run",
        "description": "tali_wit.run",
        "peekOfCode": "def instantiate_callbacks(callback_dict: dict) -> List[Callback]:\n    callbacks = []\n    for cb_conf in callback_dict.values():\n        callbacks.append(instantiate(cb_conf))\n    return callbacks\n@hydra.main(config_path=None, config_name=\"config\", version_base=None)\ndef run(cfg: BaseConfig) -> None:\n    ckpt_path, repo_url = create_hf_model_repo_and_download_maybe(cfg)\n    if ckpt_path is not None:\n        logger.info(",
        "detail": "tali_wit.run",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "tali_wit.run",
        "description": "tali_wit.run",
        "peekOfCode": "def run(cfg: BaseConfig) -> None:\n    ckpt_path, repo_url = create_hf_model_repo_and_download_maybe(cfg)\n    if ckpt_path is not None:\n        logger.info(\n            f\"ckpt_path: {ckpt_path}, exists: {ckpt_path.exists()}, resume: {cfg.resume}, not resume: {not cfg.resume}\"\n        )\n    else:\n        logger.info(\n            f\"ckpt_path: {ckpt_path}, resume: {cfg.resume}, not resume: {not cfg.resume}\"\n        )",
        "detail": "tali_wit.run",
        "documentation": {}
    },
    {
        "label": "]",
        "kind": 5,
        "importPath": "tali_wit.run",
        "description": "tali_wit.run",
        "peekOfCode": "] = \"1\"  # Makes sure that stack traces produced by hydra instantiation functions produce\n# traceback errors related to the modules they built, rather than generic instantiate related errors that\n# are generally useless for debugging\nos.environ[\n    \"TORCH_DISTRIBUTED_DEBUG\"\n] = \"DETAIL\"  # extremely useful when debugging DDP setups\ninstall()  # beautiful and clean tracebacks for debugging\nfrom typing import List, Optional\nimport hydra\nimport torch",
        "detail": "tali_wit.run",
        "documentation": {}
    },
    {
        "label": "]",
        "kind": 5,
        "importPath": "tali_wit.run",
        "description": "tali_wit.run",
        "peekOfCode": "] = \"DETAIL\"  # extremely useful when debugging DDP setups\ninstall()  # beautiful and clean tracebacks for debugging\nfrom typing import List, Optional\nimport hydra\nimport torch\nfrom hydra_zen import instantiate\nfrom omegaconf import OmegaConf\nfrom torch.utils.data import Dataset, Subset\nfrom tali_wit.boilerplate import Learner\nfrom tali_wit.callbacks import Callback",
        "detail": "tali_wit.run",
        "documentation": {}
    },
    {
        "label": "config_store",
        "kind": 5,
        "importPath": "tali_wit.run",
        "description": "tali_wit.run",
        "peekOfCode": "config_store = collect_config_store()\nlogger = get_logger(name=__name__)\ndef instantiate_callbacks(callback_dict: dict) -> List[Callback]:\n    callbacks = []\n    for cb_conf in callback_dict.values():\n        callbacks.append(instantiate(cb_conf))\n    return callbacks\n@hydra.main(config_path=None, config_name=\"config\", version_base=None)\ndef run(cfg: BaseConfig) -> None:\n    ckpt_path, repo_url = create_hf_model_repo_and_download_maybe(cfg)",
        "detail": "tali_wit.run",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tali_wit.run",
        "description": "tali_wit.run",
        "peekOfCode": "logger = get_logger(name=__name__)\ndef instantiate_callbacks(callback_dict: dict) -> List[Callback]:\n    callbacks = []\n    for cb_conf in callback_dict.values():\n        callbacks.append(instantiate(cb_conf))\n    return callbacks\n@hydra.main(config_path=None, config_name=\"config\", version_base=None)\ndef run(cfg: BaseConfig) -> None:\n    ckpt_path, repo_url = create_hf_model_repo_and_download_maybe(cfg)\n    if ckpt_path is not None:",
        "detail": "tali_wit.run",
        "documentation": {}
    },
    {
        "label": "instantiate_callbacks",
        "kind": 2,
        "importPath": "tali_wit.run_data",
        "description": "tali_wit.run_data",
        "peekOfCode": "def instantiate_callbacks(callback_dict: dict) -> List[Callback]:\n    callbacks = []\n    for cb_conf in callback_dict.values():\n        callbacks.append(instantiate(cb_conf))\n    return callbacks\n@hydra.main(config_path=None, config_name=\"config\", version_base=None)\ndef run(cfg: BaseConfig) -> None:\n    print(pretty_config(cfg, resolve=True))\n    set_seed(seed=cfg.seed)\n    train_datasets = []",
        "detail": "tali_wit.run_data",
        "documentation": {}
    },
    {
        "label": "run",
        "kind": 2,
        "importPath": "tali_wit.run_data",
        "description": "tali_wit.run_data",
        "peekOfCode": "def run(cfg: BaseConfig) -> None:\n    print(pretty_config(cfg, resolve=True))\n    set_seed(seed=cfg.seed)\n    train_datasets = []\n    for dataset_name, (batch_size, dataset) in cfg.dataset.items():\n        logger.info(f\"Setting up {dataset_name} train dataset\")\n        train_dataset: Dataset = instantiate(\n            dataset,\n            set_name=\"train\",\n            infinite_sampling=True,",
        "detail": "tali_wit.run_data",
        "documentation": {}
    },
    {
        "label": "]",
        "kind": 5,
        "importPath": "tali_wit.run_data",
        "description": "tali_wit.run_data",
        "peekOfCode": "] = \"1\"  # Makes sure that stack traces produced by hydra instantiation functions produce\n# traceback errors related to the modules they built, rather than generic instantiate related errors that\n# are generally useless for debugging\nos.environ[\n    \"TORCH_DISTRIBUTED_DEBUG\"\n] = \"DETAIL\"  # extremely useful when debugging DDP setups\ninstall()  # beautiful and clean tracebacks for debugging\nfrom typing import List, Optional\nimport hydra\nimport torch",
        "detail": "tali_wit.run_data",
        "documentation": {}
    },
    {
        "label": "]",
        "kind": 5,
        "importPath": "tali_wit.run_data",
        "description": "tali_wit.run_data",
        "peekOfCode": "] = \"DETAIL\"  # extremely useful when debugging DDP setups\ninstall()  # beautiful and clean tracebacks for debugging\nfrom typing import List, Optional\nimport hydra\nimport torch\nfrom hydra_zen import instantiate\nfrom omegaconf import OmegaConf\nfrom torch.utils.data import Dataset, Subset\nfrom tali_wit.boilerplate import Learner\nfrom tali_wit.callbacks import Callback",
        "detail": "tali_wit.run_data",
        "documentation": {}
    },
    {
        "label": "config_store",
        "kind": 5,
        "importPath": "tali_wit.run_data",
        "description": "tali_wit.run_data",
        "peekOfCode": "config_store = collect_config_store()\nlogger = get_logger(name=__name__)\ndef instantiate_callbacks(callback_dict: dict) -> List[Callback]:\n    callbacks = []\n    for cb_conf in callback_dict.values():\n        callbacks.append(instantiate(cb_conf))\n    return callbacks\n@hydra.main(config_path=None, config_name=\"config\", version_base=None)\ndef run(cfg: BaseConfig) -> None:\n    print(pretty_config(cfg, resolve=True))",
        "detail": "tali_wit.run_data",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tali_wit.run_data",
        "description": "tali_wit.run_data",
        "peekOfCode": "logger = get_logger(name=__name__)\ndef instantiate_callbacks(callback_dict: dict) -> List[Callback]:\n    callbacks = []\n    for cb_conf in callback_dict.values():\n        callbacks.append(instantiate(cb_conf))\n    return callbacks\n@hydra.main(config_path=None, config_name=\"config\", version_base=None)\ndef run(cfg: BaseConfig) -> None:\n    print(pretty_config(cfg, resolve=True))\n    set_seed(seed=cfg.seed)",
        "detail": "tali_wit.run_data",
        "documentation": {}
    },
    {
        "label": "Trainer",
        "kind": 6,
        "importPath": "tali_wit.trainers",
        "description": "tali_wit.trainers",
        "peekOfCode": "class Trainer(object):\n    def __init__(self):\n        pass\n@dataclass\nclass TrainerOutput:\n    opt_loss: torch.Tensor\n    global_step: int\n    metrics: Dict[str, Any]\n    phase_name: str\n    experiment_tracker: Any = None",
        "detail": "tali_wit.trainers",
        "documentation": {}
    },
    {
        "label": "TrainerOutput",
        "kind": 6,
        "importPath": "tali_wit.trainers",
        "description": "tali_wit.trainers",
        "peekOfCode": "class TrainerOutput:\n    opt_loss: torch.Tensor\n    global_step: int\n    metrics: Dict[str, Any]\n    phase_name: str\n    experiment_tracker: Any = None\nclass ClassificationTrainer(Trainer):\n    def __init__(\n        self,\n        optimizer: torch.optim.Optimizer,",
        "detail": "tali_wit.trainers",
        "documentation": {}
    },
    {
        "label": "ClassificationTrainer",
        "kind": 6,
        "importPath": "tali_wit.trainers",
        "description": "tali_wit.trainers",
        "peekOfCode": "class ClassificationTrainer(Trainer):\n    def __init__(\n        self,\n        optimizer: torch.optim.Optimizer,\n        scheduler: torch.optim.lr_scheduler._LRScheduler = None,\n        scheduler_interval: str = Interval.STEP,\n        experiment_tracker: Any = None,\n    ):\n        super().__init__()\n        self.optimizer = optimizer",
        "detail": "tali_wit.trainers",
        "documentation": {}
    },
    {
        "label": "get_dict_shapes",
        "kind": 2,
        "importPath": "tali_wit.trainers",
        "description": "tali_wit.trainers",
        "peekOfCode": "def get_dict_shapes(x):\n    print(x)\n    if not isinstance(x, dict):\n        return get_dict_shapes(x.__dict__)\n    return {\n        key: value.shape if isinstance(value, torch.Tensor) else len(value)\n        for key, value in x.items()\n    }\nclass Trainer(object):\n    def __init__(self):",
        "detail": "tali_wit.trainers",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tali_wit.trainers",
        "description": "tali_wit.trainers",
        "peekOfCode": "logger = get_logger(__name__)\ndef get_dict_shapes(x):\n    print(x)\n    if not isinstance(x, dict):\n        return get_dict_shapes(x.__dict__)\n    return {\n        key: value.shape if isinstance(value, torch.Tensor) else len(value)\n        for key, value in x.items()\n    }\nclass Trainer(object):",
        "detail": "tali_wit.trainers",
        "documentation": {}
    },
    {
        "label": "get_logger",
        "kind": 2,
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "peekOfCode": "def get_logger(\n    name=__name__, logging_level: str = None, set_rich: bool = False\n) -> logging.Logger:\n    \"\"\"Initializes multi-GPU-friendly python command line logger.\"\"\"\n    logger = logging.getLogger(name)\n    logging_level = logging_level or logging.INFO\n    logger.setLevel(logging_level)\n    if set_rich:\n        ch = RichHandler()\n        # create formatter",
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "get_hydra_config",
        "kind": 2,
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "peekOfCode": "def get_hydra_config(logger_level: str = \"INFO\"):\n    return dict(\n        job_logging=dict(\n            version=1,\n            formatters=dict(\n                simple=dict(\n                    level=logger_level,\n                    format=\"%(message)s\",\n                    datefmt=\"[%X]\",\n                )",
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "timeout",
        "kind": 2,
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "peekOfCode": "def timeout(timeout_secs: int):\n    def wrapper(func):\n        @wraps(func)\n        def time_limited(*args, **kwargs):\n            # Register an handler for the timeout\n            def handler(signum, frame):\n                raise Exception(f\"Timeout for function '{func.__name__}'\")\n            # Register the signal function handler\n            signal.signal(signal.SIGALRM, handler)\n            # Define a timeout for your function",
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "demo_logger",
        "kind": 2,
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "peekOfCode": "def demo_logger():\n    logger = get_logger(__name__)\n    logger.info(\"Hello World\")\n    logger.debug(\"Debugging\")\n    logger.warning(\"Warning\")\n    logger.error(\"Error\")\n    logger.critical(\"Critical\")\n    logger.exception(\"Exception\")\ndef set_seed(seed: int):\n    accelerate.utils.set_seed(seed)",
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "set_seed",
        "kind": 2,
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "peekOfCode": "def set_seed(seed: int):\n    accelerate.utils.set_seed(seed)\ndef pretty_config(\n    config: DictConfig,\n    resolve: bool = True,\n):\n    \"\"\"Prints content of DictConfig using Rich library and its tree structure.\n    Args:\n        config (DictConfig): Configuration composed by Hydra.\n        fields (Sequence[str], optional): Determines which main fields from config will",
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "pretty_config",
        "kind": 2,
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "peekOfCode": "def pretty_config(\n    config: DictConfig,\n    resolve: bool = True,\n):\n    \"\"\"Prints content of DictConfig using Rich library and its tree structure.\n    Args:\n        config (DictConfig): Configuration composed by Hydra.\n        fields (Sequence[str], optional): Determines which main fields from config will\n        be printed and in what order.\n        resolve (bool, optional): Whether to resolve reference fields of DictConfig.",
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "save_json",
        "kind": 2,
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "peekOfCode": "def save_json(filepath: Union[str, pathlib.Path], dict_to_store: Dict, overwrite=True):\n    \"\"\"\n    Saves a metrics .json file with the metrics\n    :param log_dir: Directory of log\n    :param metrics_file_name: Name of .csv file\n    :param dict_to_store: A dict of metrics to add in the file\n    :param overwrite: If True overwrites any existing files with the same filepath,\n    if False adds metrics to existing\n    \"\"\"\n    if isinstance(filepath, str):",
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "load_json",
        "kind": 2,
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "peekOfCode": "def load_json(filepath: Union[str, pathlib.Path]):\n    \"\"\"\n    Loads the metrics in a dictionary.\n    :param log_dir: The directory in which the log is saved\n    :param metrics_file_name: The name of the metrics file\n    :return: A dict with the metrics\n    \"\"\"\n    if isinstance(filepath, str):\n        filepath = pathlib.Path(filepath)\n    with open(filepath, \"rb\") as json_file:",
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "download_model_with_name",
        "kind": 2,
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "peekOfCode": "def download_model_with_name(\n    hf_repo_path, hf_cache_dir, model_name, download_only_if_finished=False\n):\n    if not pathlib.Path(\n        pathlib.Path(hf_cache_dir) / \"checkpoints\" / f\"{model_name}\"\n    ).exists():\n        pathlib.Path(\n            pathlib.Path(hf_cache_dir) / \"checkpoints\" / f\"{model_name}\"\n        ).mkdir(parents=True, exist_ok=True)\n    config_filepath = hf_hub_download(",
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "create_hf_model_repo_and_download_maybe",
        "kind": 2,
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "peekOfCode": "def create_hf_model_repo_and_download_maybe(cfg: Any):\n    import yaml\n    from huggingface_hub import HfApi\n    if cfg.download_checkpoint_with_name is not None and cfg.download_latest is True:\n        raise ValueError(\n            \"Cannot use both continue_from_checkpoint_with_name and continue_from_latest\"\n        )\n    hf_repo_path = cfg.hf_repo_path\n    login(token=os.environ[\"HF_TOKEN\"], add_to_git_credential=True)\n    print(",
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tali_wit.utils",
        "description": "tali_wit.utils",
        "peekOfCode": "logger = get_logger(name=__name__)\ndef download_model_with_name(\n    hf_repo_path, hf_cache_dir, model_name, download_only_if_finished=False\n):\n    if not pathlib.Path(\n        pathlib.Path(hf_cache_dir) / \"checkpoints\" / f\"{model_name}\"\n    ).exists():\n        pathlib.Path(\n            pathlib.Path(hf_cache_dir) / \"checkpoints\" / f\"{model_name}\"\n        ).mkdir(parents=True, exist_ok=True)",
        "detail": "tali_wit.utils",
        "documentation": {}
    },
    {
        "label": "WITBase",
        "kind": 6,
        "importPath": "tali_wit.wit",
        "description": "tali_wit.wit",
        "peekOfCode": "class WITBase(Dataset):\n    def __init__(\n        self,\n        wit_dataset_dir: str,\n        tali_dataset_dir: str,\n        image_size: int,\n        set_name: str,\n        num_samples_per_episode: int,\n        deterministic_sampling: bool = False,\n        infinite_sampling: bool = False,",
        "detail": "tali_wit.wit",
        "documentation": {}
    },
    {
        "label": "WITBaseTransform",
        "kind": 6,
        "importPath": "tali_wit.wit",
        "description": "tali_wit.wit",
        "peekOfCode": "class WITBaseTransform:\n    def __init__(\n        self,\n        image_size,\n        deterministic_sampling: bool = False,\n        priority_caption_language: Optional[str] = None,\n    ):\n        self.image_size = image_size\n        self.image_transform = default_image_transforms(self.image_size)\n        self.deterministic_sampling = deterministic_sampling",
        "detail": "tali_wit.wit",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "tali_wit.wit",
        "description": "tali_wit.wit",
        "peekOfCode": "logger = get_logger(__name__)\n@configurable\nclass WITBase(Dataset):\n    def __init__(\n        self,\n        wit_dataset_dir: str,\n        tali_dataset_dir: str,\n        image_size: int,\n        set_name: str,\n        num_samples_per_episode: int,",
        "detail": "tali_wit.wit",
        "documentation": {}
    },
    {
        "label": "SyntheticDataset",
        "kind": 6,
        "importPath": "async_dataloading",
        "description": "async_dataloading",
        "peekOfCode": "class SyntheticDataset(Dataset):\n    def __init__(self, a, b, noise_std, num_samples):\n        self.a = a\n        self.b = b\n        self.noise_std = noise_std\n        self.num_samples = num_samples\n    def __len__(self):\n        return self.num_samples\n    def __getitem__(self, idx):\n        x = torch.randn(3, 224, 224)",
        "detail": "async_dataloading",
        "documentation": {}
    },
    {
        "label": "LinearRegressionModel",
        "kind": 6,
        "importPath": "async_dataloading",
        "description": "async_dataloading",
        "peekOfCode": "class LinearRegressionModel(nn.Module):\n    def __init__(self):\n        super(LinearRegressionModel, self).__init__()\n        self.in_linear = nn.Linear(in_features=3 * 224 * 224, out_features=1024)\n        self.middle_linear = nn.Linear(in_features=1024, out_features=1024)\n        self.out_linear = nn.Linear(in_features=1024, out_features=1)\n    def forward(self, x):\n        out = F.gelu(self.in_linear(x.view(x.shape[0], -1)))\n        out = F.gelu(self.middle_linear(out))\n        out = self.out_linear(out)",
        "detail": "async_dataloading",
        "documentation": {}
    },
    {
        "label": "AsyncGeneratorWrapper",
        "kind": 6,
        "importPath": "async_dataloading",
        "description": "async_dataloading",
        "peekOfCode": "class AsyncGeneratorWrapper:\n    def __init__(self, data_loaders: List[DataLoader]):\n        self.data_loaders = data_loaders\n        self.queue = asyncio.Queue()\n    def wrapper(self, data_loader):\n        for value in data_loader:\n            self.queue.put_nowait(value)\n        self.queue.put_nowait(None)\n    async def process_queue(self):\n        num_none_received = 0",
        "detail": "async_dataloading",
        "documentation": {}
    },
    {
        "label": "datasets",
        "kind": 5,
        "importPath": "async_dataloading",
        "description": "async_dataloading",
        "peekOfCode": "datasets = [\n    SyntheticDataset(a=2, b=3, noise_std=0.1, num_samples=100),\n    SyntheticDataset(a=2, b=3, noise_std=0.1, num_samples=200),\n    SyntheticDataset(a=2, b=3, noise_std=0.1, num_samples=300),\n]\ndata_loaders = [DataLoader(dataset, batch_size=1, shuffle=True) for dataset in datasets]\n#  Create the AsyncGeneratorWrapper instance\nasync_data_generator = AsyncGeneratorWrapper(data_loaders)\n#  Initialize the model, loss function, and optimizer\nmodel = LinearRegressionModel()",
        "detail": "async_dataloading",
        "documentation": {}
    },
    {
        "label": "data_loaders",
        "kind": 5,
        "importPath": "async_dataloading",
        "description": "async_dataloading",
        "peekOfCode": "data_loaders = [DataLoader(dataset, batch_size=1, shuffle=True) for dataset in datasets]\n#  Create the AsyncGeneratorWrapper instance\nasync_data_generator = AsyncGeneratorWrapper(data_loaders)\n#  Initialize the model, loss function, and optimizer\nmodel = LinearRegressionModel()\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n#  Train the model\nnum_epochs = 10\nasyncio.run(",
        "detail": "async_dataloading",
        "documentation": {}
    },
    {
        "label": "async_data_generator",
        "kind": 5,
        "importPath": "async_dataloading",
        "description": "async_dataloading",
        "peekOfCode": "async_data_generator = AsyncGeneratorWrapper(data_loaders)\n#  Initialize the model, loss function, and optimizer\nmodel = LinearRegressionModel()\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n#  Train the model\nnum_epochs = 10\nasyncio.run(\n    train_model(\n        async_data_generator,",
        "detail": "async_dataloading",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "async_dataloading",
        "description": "async_dataloading",
        "peekOfCode": "model = LinearRegressionModel()\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n#  Train the model\nnum_epochs = 10\nasyncio.run(\n    train_model(\n        async_data_generator,\n        model,\n        criterion,",
        "detail": "async_dataloading",
        "documentation": {}
    },
    {
        "label": "criterion",
        "kind": 5,
        "importPath": "async_dataloading",
        "description": "async_dataloading",
        "peekOfCode": "criterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n#  Train the model\nnum_epochs = 10\nasyncio.run(\n    train_model(\n        async_data_generator,\n        model,\n        criterion,\n        optimizer,",
        "detail": "async_dataloading",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "async_dataloading",
        "description": "async_dataloading",
        "peekOfCode": "optimizer = optim.SGD(model.parameters(), lr=0.01)\n#  Train the model\nnum_epochs = 10\nasyncio.run(\n    train_model(\n        async_data_generator,\n        model,\n        criterion,\n        optimizer,\n        num_epochs,",
        "detail": "async_dataloading",
        "documentation": {}
    },
    {
        "label": "num_epochs",
        "kind": 5,
        "importPath": "async_dataloading",
        "description": "async_dataloading",
        "peekOfCode": "num_epochs = 10\nasyncio.run(\n    train_model(\n        async_data_generator,\n        model,\n        criterion,\n        optimizer,\n        num_epochs,\n        len(async_data_generator),\n    )",
        "detail": "async_dataloading",
        "documentation": {}
    },
    {
        "label": "processor",
        "kind": 5,
        "importPath": "debug",
        "description": "debug",
        "peekOfCode": "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v2\")\nmodel = WhisperForConditionalGeneration.from_pretrained(\n    \"openai/whisper-large-v2\"\n)\nmodel.config.forced_decoder_ids = None\n# load dummy dataset and read audio files\nds = load_dataset(\n    \"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\"\n)\nsampling_rate = ds[0][\"audio\"][\"sampling_rate\"]",
        "detail": "debug",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "debug",
        "description": "debug",
        "peekOfCode": "model = WhisperForConditionalGeneration.from_pretrained(\n    \"openai/whisper-large-v2\"\n)\nmodel.config.forced_decoder_ids = None\n# load dummy dataset and read audio files\nds = load_dataset(\n    \"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\"\n)\nsampling_rate = ds[0][\"audio\"][\"sampling_rate\"]\nsample = (",
        "detail": "debug",
        "documentation": {}
    },
    {
        "label": "model.config.forced_decoder_ids",
        "kind": 5,
        "importPath": "debug",
        "description": "debug",
        "peekOfCode": "model.config.forced_decoder_ids = None\n# load dummy dataset and read audio files\nds = load_dataset(\n    \"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\"\n)\nsampling_rate = ds[0][\"audio\"][\"sampling_rate\"]\nsample = (\n    torch.tensor(ds[0][\"audio\"][\"array\"]).unsqueeze(0).repeat(8, 1).unbind(0)\n)\ninput_features = processor(",
        "detail": "debug",
        "documentation": {}
    },
    {
        "label": "ds",
        "kind": 5,
        "importPath": "debug",
        "description": "debug",
        "peekOfCode": "ds = load_dataset(\n    \"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\"\n)\nsampling_rate = ds[0][\"audio\"][\"sampling_rate\"]\nsample = (\n    torch.tensor(ds[0][\"audio\"][\"array\"]).unsqueeze(0).repeat(8, 1).unbind(0)\n)\ninput_features = processor(\n    sample, sampling_rate=sampling_rate, return_tensors=\"pt\"\n).input_features",
        "detail": "debug",
        "documentation": {}
    },
    {
        "label": "sampling_rate",
        "kind": 5,
        "importPath": "debug",
        "description": "debug",
        "peekOfCode": "sampling_rate = ds[0][\"audio\"][\"sampling_rate\"]\nsample = (\n    torch.tensor(ds[0][\"audio\"][\"array\"]).unsqueeze(0).repeat(8, 1).unbind(0)\n)\ninput_features = processor(\n    sample, sampling_rate=sampling_rate, return_tensors=\"pt\"\n).input_features\n# # generate token ids\n# predicted_ids = model.generate(input_features)\n# # decode token ids to text",
        "detail": "debug",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "debug",
        "description": "debug",
        "peekOfCode": "sample = (\n    torch.tensor(ds[0][\"audio\"][\"array\"]).unsqueeze(0).repeat(8, 1).unbind(0)\n)\ninput_features = processor(\n    sample, sampling_rate=sampling_rate, return_tensors=\"pt\"\n).input_features\n# # generate token ids\n# predicted_ids = model.generate(input_features)\n# # decode token ids to text\n# transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)",
        "detail": "debug",
        "documentation": {}
    },
    {
        "label": "input_features",
        "kind": 5,
        "importPath": "debug",
        "description": "debug",
        "peekOfCode": "input_features = processor(\n    sample, sampling_rate=sampling_rate, return_tensors=\"pt\"\n).input_features\n# # generate token ids\n# predicted_ids = model.generate(input_features)\n# # decode token ids to text\n# transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)\n# transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)",
        "detail": "debug",
        "documentation": {}
    }
]